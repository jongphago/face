{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from fpt.data import join_face_df\n",
    "from fpt.split import read_split\n",
    "from fpt.path import DTFR, UTIL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face = join_face_df(DTFR, \"aihub_family\")  # 16.1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_CATEGORY = \"train\"\n",
    "valid_uuids = read_split(TASK_CATEGORY)\n",
    "x_valid = face.loc[valid_uuids]\n",
    "x_valid = x_valid.reset_index().reset_index().set_index(\"uuid\")\n",
    "x_valid.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample group\n",
    "# x_valid.groupby('target').index.apply(list).to_frame().head()\n",
    "# x_valid.groupby(['family_id', 'personal_id', 'category']).index.apply(list).to_frame().head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(22)\n",
    "NUM_FOLDS = 10\n",
    "NUM_PAIRS = 300\n",
    "CATEGORY = \"Age\"\n",
    "target_pair = f\"pairs/{TASK_CATEGORY}/pairs_{CATEGORY}.txt\"\n",
    "os.makedirs(os.path.dirname(target_pair), exist_ok=True)\n",
    "\n",
    "is_family = x_valid.category == CATEGORY\n",
    "family_valid = x_valid[is_family]\n",
    "idx_family_valid = family_valid.groupby(\"target\").index.apply(list).to_frame()\n",
    "\n",
    "with open(target_pair, \"w\") as f:\n",
    "    f.write(f\"{NUM_FOLDS} {NUM_PAIRS}\\n\")\n",
    "    for n in range(NUM_FOLDS):\n",
    "        # matched\n",
    "        matched_sample = idx_family_valid.sample(\n",
    "            n=300, replace=False, random_state=n\n",
    "        ).sort_values(\"target\")\n",
    "        for key, value in matched_sample.iterrows():\n",
    "            idxs = value.loc[\"index\"]\n",
    "            selected = np.random.choice(idxs, size=2, replace=False)\n",
    "            f.write(f\"{key:8s}\\t{valid_uuids[selected[0]]}\\t{valid_uuids[selected[1]]}\")\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "        # mismatched\n",
    "        for i in range(300):\n",
    "            mismatched_sample = idx_family_valid.sample(\n",
    "                n=2, replace=False, random_state=n * 1000 + i\n",
    "            ).sort_values(\"target\")\n",
    "            sampled = [\n",
    "                [key, np.random.choice(value.loc[\"index\"], replace=False)]\n",
    "                for key, value in mismatched_sample.iterrows()\n",
    "            ]\n",
    "            target_a, idx_a, target_b, idx_b = np.array(sampled).flatten().tolist()\n",
    "            uuid_a, uuid_b = valid_uuids[int(idx_a)], valid_uuids[int(idx_b)]\n",
    "            f.write(f\"{target_a:<8}\\t{uuid_a}\\t{target_b:<8}\\t{uuid_b}\")\n",
    "            f.write(\"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get New Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fpt.data import join_face_df\n",
    "from fpt.split import read_split\n",
    "from fpt.path import DTFR\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face = join_face_df(DTFR, \"aihub_family\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_CATEGORY = \"valid\"\n",
    "valid_uuids = read_split(TASK_CATEGORY)\n",
    "x_valid = face.loc[valid_uuids]\n",
    "x_valid = x_valid.reset_index().reset_index().set_index(\"uuid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = x_valid.groupby([\"family_id\", \"age_group\", \"gender\", \"personal_id\"]).agg(list)[\n",
    "    [\"index\"]\n",
    "]\n",
    "\n",
    "# 인덱스 쌍을 저장할 빈 리스트를 생성합니다.\n",
    "index_pairs = []\n",
    "\n",
    "# 각 그룹에 대해 인덱스 쌍을 생성합니다.\n",
    "for _, group in df.groupby([\"family_id\", \"age_group\", \"gender\"]):\n",
    "    index_list = group[\"index\"].tolist()\n",
    "\n",
    "    # 그룹의 인덱스 리스트에 두 개 이상의 원소가 있는 경우에만 조합을 생성합니다.\n",
    "    if len(index_list) >= 2:\n",
    "        for candidate in itertools.combinations(index_list, 2):\n",
    "            for pair in itertools.product(*candidate):\n",
    "                index_pairs.append([*group.index[0][:3], pair])\n",
    "\n",
    "# 인덱스 쌍을 출력합니다.\n",
    "pd.DataFrame(index_pairs, columns=[\"family_id\", \"age_group\", \"gender\", \"pairs\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CASE1: 가족 관계에 있는 얼굴쌍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from fpt.data import join_face_df\n",
    "from fpt.split import read_split\n",
    "from fpt.path import DTFR\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face = join_face_df(DTFR, \"aihub_family\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(22)\n",
    "NUM_FOLDS = 10\n",
    "NUM_PAIRS = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORY = \"CASE1\"\n",
    "TASK_CATEGORY = \"test\"\n",
    "target_pair = f\"pairs/{TASK_CATEGORY}/pairs_{CATEGORY}.txt\"\n",
    "os.makedirs(os.path.dirname(target_pair), exist_ok=True)\n",
    "print(target_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_uuids = read_split(TASK_CATEGORY)\n",
    "x_valid = face.loc[valid_uuids]\n",
    "x_valid = x_valid.reset_index().reset_index().set_index(\"uuid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = x_valid.groupby([\"family_id\", \"personal_id\"]).agg(list)[[\"index\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 그룹에 대해 인덱스 쌍을 생성합니다.\n",
    "total_matched_list = []\n",
    "for index, value in df.itertuples():\n",
    "    for candidate in itertools.combinations(value, 2):\n",
    "        total_matched_list.append([index[0], candidate])\n",
    "total_matched_pairs = pd.DataFrame(total_matched_list, columns=[\"family_id\", \"pairs\"])\n",
    "selected_matched_pairs = total_matched_pairs.sample(\n",
    "    n=3000, replace=False, random_state=22\n",
    ")\n",
    "\n",
    "# 인덱스 쌍을 저장할 빈 리스트를 생성합니다.\n",
    "total_mismatched_list = []\n",
    "\n",
    "# 각 그룹에 대해 인덱스 쌍을 생성합니다.\n",
    "for _, group in df.groupby([\"family_id\"]):\n",
    "    index_list = group[\"index\"].tolist()\n",
    "\n",
    "    # 그룹의 인덱스 리스트에 두 개 이상의 원소가 있는 경우에만 조합을 생성합니다.\n",
    "    if len(index_list) >= 2:\n",
    "        for candidate in itertools.combinations(index_list, 2):\n",
    "            for pair in itertools.product(*candidate):\n",
    "                total_mismatched_list.append([*group.index[0][:1], pair])\n",
    "\n",
    "# 인덱스 쌍을 출력합니다.\n",
    "total_mismatched_pairs = pd.DataFrame(\n",
    "    total_mismatched_list, columns=[\"family_id\", \"pairs\"]\n",
    ")\n",
    "selected_mismatched_pairs = total_mismatched_pairs.sample(\n",
    "    n=3000, replace=False, random_state=22\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_matched = [\n",
    "    group\n",
    "    for _, group in selected_matched_pairs.groupby(\n",
    "        np.arange(len(selected_matched_pairs)) // NUM_PAIRS\n",
    "    )\n",
    "]\n",
    "dfs_mismatched = [\n",
    "    group\n",
    "    for _, group in selected_mismatched_pairs.groupby(\n",
    "        np.arange(len(selected_mismatched_pairs)) // NUM_PAIRS\n",
    "    )\n",
    "]\n",
    "\n",
    "with open(target_pair, \"w\") as f:\n",
    "    f.write(f\"{NUM_FOLDS} {NUM_PAIRS}\\n\")\n",
    "    for df_matched, df_mismatched in zip(dfs_matched, dfs_mismatched):\n",
    "        for row in df_matched.itertuples():\n",
    "            idx1, idx2 = row.pairs\n",
    "            target = x_valid.iloc[idx1].target\n",
    "            assert target == x_valid.iloc[idx2].target\n",
    "            name1 = x_valid.iloc[idx1].name\n",
    "            name2 = x_valid.iloc[idx2].name\n",
    "            f.write(f\"{target:8s}\\t{name1}\\t{name2}\\n\")\n",
    "\n",
    "        for row in df_mismatched.itertuples():\n",
    "            idx1, idx2 = row.pairs\n",
    "            target1 = x_valid.iloc[idx1].target\n",
    "            target2 = x_valid.iloc[idx2].target\n",
    "            assert x_valid.iloc[idx1].family_id == x_valid.iloc[idx2].family_id\n",
    "            assert target1 != target2\n",
    "            name1 = x_valid.iloc[idx1].name\n",
    "            name2 = x_valid.iloc[idx2].name\n",
    "            f.write(f\"{target1:8s}\\t{name1}\\t{target2:8s}\\t{name2}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CASE1C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORY = \"CASE1C\"\n",
    "DIR_CATEGORY = \"test\"\n",
    "TASK_CATEGORY = \"test\"\n",
    "\n",
    "target_pair = f\"pairs/{DIR_CATEGORY}/pairs_{CATEGORY}.txt\"\n",
    "os.makedirs(os.path.dirname(target_pair), exist_ok=True)\n",
    "print(target_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(22)\n",
    "unique_family_id = x_valid.family_id.unique()\n",
    "unique_family_id_total_pairs = list(combinations(unique_family_id, 2))\n",
    "index_list = np.random.choice(len(unique_family_id_total_pairs), 6000, replace=True)\n",
    "selected_family_pairs = np.array(unique_family_id_total_pairs)[index_list]\n",
    "with open(target_pair, \"w\") as f:\n",
    "    f.write(f\"{NUM_FOLDS} {NUM_PAIRS}\\n\")\n",
    "    for fids in selected_family_pairs:\n",
    "\n",
    "        def get_target_and_name(family_id, df=x_valid):\n",
    "            row = df[df.family_id == family_id].sample()\n",
    "            target, name = row.target.item(), row.iloc[0].name\n",
    "            return target, name\n",
    "\n",
    "        fid1, fid2 = fids\n",
    "        target1, name1 = get_target_and_name(fid1)\n",
    "        target2, name2 = get_target_and_name(fid2)\n",
    "        f.write(f\"{target1:8s}\\t{name1}\\t{target2:8s}\\t{name2}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pairs/test/pairs_CASE1C.txt`\n",
    "```markdown\n",
    "10 300\n",
    "F0836-M \t7649eabb-da97-4bd6-9e66-adeee88c69cc\tF0900-D \ted80801a-5c34-4a6a-bb8f-20deb0ca9ca4\n",
    "F0891-S \t749c628a-cb31-4179-9b26-19ccfa5f6018\tF0895-D \te3cfbe54-71d4-461c-861e-bb058ed594c9\n",
    "F0804-D \t9d5d61c5-f8d9-485c-a912-f156e27ebc3f\tF0867-S3\tf94cd228-762b-4e0c-a3ce-a50eff6cb049\n",
    "F0873-M \t6dc0dfb0-52c6-40ee-9f44-fb7a546560fc\tF0889-D \t326b1e97-d796-4af9-982d-7ec73bff9c10\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CASE2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from fpt.data import join_face_df\n",
    "from fpt.split import read_split\n",
    "from fpt.path import DTFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face = join_face_df(DTFR, \"aihub_family\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FOLDS = 10\n",
    "NUM_PAIRS = 300\n",
    "CATEGORY = \"CASE2\"\n",
    "DIR_CATEGORY = \"temp\"\n",
    "TASK_CATEGORY = \"test\"\n",
    "\n",
    "target_pair = f\"pairs/{DIR_CATEGORY}/pairs_{CATEGORY}.txt\"\n",
    "os.makedirs(os.path.dirname(target_pair), exist_ok=True)\n",
    "print(target_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_uuids = read_split(TASK_CATEGORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid = face.loc[valid_uuids]\n",
    "x_valid = x_valid.reset_index().reset_index().set_index(\"uuid\")\n",
    "df = x_valid.groupby([\"target\", \"age_group\"]).agg(list)[['index']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_same_age_list = []  # 52310\n",
    "for index, value in df.itertuples():\n",
    "    for candidate in itertools.combinations(value, 2):\n",
    "        total_same_age_list.append([*index, candidate])\n",
    "        \n",
    "total_same_age_pairs = pd.DataFrame(total_same_age_list, columns=[\"family_id\", \"age_group\", \"pairs\"])\n",
    "selected_same_age_pairs = total_same_age_pairs.sample(\n",
    "    n=6000, replace=False, random_state=22\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAME personal_id & SAME age_group\n",
    "with open(target_pair, \"w\") as f:\n",
    "    f.write(f\"{NUM_FOLDS} {NUM_PAIRS}\\n\")\n",
    "    for row in selected_same_age_pairs.itertuples():\n",
    "        idx1, idx2 = row.pairs\n",
    "        target = x_valid.iloc[idx1].target\n",
    "        age_group = x_valid.iloc[idx1].age_group\n",
    "        assert age_group == x_valid.iloc[idx2].age_group\n",
    "        name1 = x_valid.iloc[idx1].name\n",
    "        name2 = x_valid.iloc[idx2].name\n",
    "        f.write(f\"{target:8s}\\t{name1}\\t{name2}\\n\")\n",
    "        # break\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CASE2C:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FOLDS = 10\n",
    "NUM_PAIRS = 300\n",
    "CATEGORY = \"CASE2C\"\n",
    "DIR_CATEGORY = \"temp\"\n",
    "TASK_CATEGORY = \"test\"\n",
    "\n",
    "target_pair = f\"pairs/{DIR_CATEGORY}/pairs_{CATEGORY}.txt\"\n",
    "os.makedirs(os.path.dirname(target_pair), exist_ok=True)\n",
    "print(target_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인덱스 쌍을 저장할 빈 리스트를 생성합니다.\n",
    "total_mismatched_list = []\n",
    "\n",
    "# 각 그룹에 대해 인덱스 쌍을 생성합니다.\n",
    "for _, group in df.groupby([\"target\"]):\n",
    "    index_list = group[\"index\"].tolist()\n",
    "    # 그룹의 인덱스 리스트에 두 개 이상의 원소가 있는 경우에만 조합을 생성합니다.\n",
    "    if len(index_list) >= 2:\n",
    "        for candidate in itertools.combinations(index_list, 2):\n",
    "            for pair in itertools.product(*candidate):\n",
    "                total_mismatched_list.append([*group.index[0][:1], pair])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인덱스 쌍을 출력합니다.\n",
    "total_mismatched_pairs = pd.DataFrame(\n",
    "    total_mismatched_list, columns=[\"target\", \"pairs\"]\n",
    ")\n",
    "selected_mismatched_pairs = total_mismatched_pairs.sample(\n",
    "    n=6000, replace=False, random_state=22\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(target_pair, \"w\") as f:\n",
    "    f.write(f\"{NUM_FOLDS} {NUM_PAIRS}\\n\")\n",
    "    for row in selected_mismatched_pairs.itertuples():\n",
    "        idx1, idx2 = row.pairs\n",
    "        target1 = x_valid.iloc[idx1].target\n",
    "        target2 = x_valid.iloc[idx2].target\n",
    "        assert x_valid.iloc[idx1].age_group != x_valid.iloc[idx2].age_group\n",
    "        assert target1 == target2\n",
    "        name1 = x_valid.iloc[idx1].name\n",
    "        name2 = x_valid.iloc[idx2].name\n",
    "        f.write(f\"{target1:8s}\\t{name1}\\t{name2}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fpt.data import join_face_df\n",
    "from fpt.split import read_split\n",
    "from fpt.path import DTFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FOLDS = 10\n",
    "NUM_PAIRS = 300"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face = join_face_df(DTFR, \"aihub_family\")\n",
    "valid_uuids = read_split(\"test\")\n",
    "x_test = face.loc[valid_uuids]\n",
    "x_test = x_test.reset_index().reset_index().set_index(\"uuid\")\n",
    "df = x_test.groupby([\"gender\"]).agg(list)[['index']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BASIC-G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORY = \"BASIC-G\"\n",
    "dir_category = \"test\"\n",
    "\n",
    "target_pair = f\"pairs/{dir_category}/pairs_{CATEGORY}.txt\"\n",
    "os.makedirs(os.path.dirname(target_pair), exist_ok=True)\n",
    "print(target_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(22)\n",
    "unique_group = [\"Male\", \"Female\"]\n",
    "index_list = np.random.choice(len(unique_group), 6000, replace=True)\n",
    "selected_group = np.array(unique_group)[index_list]\n",
    "\n",
    "with open(target_pair, \"w\") as f:\n",
    "    f.write(f\"{NUM_FOLDS} {NUM_PAIRS}\\n\")\n",
    "    for group in tqdm(selected_group):\n",
    "        pid1, pid2 = random.sample(df.loc[group][\"index\"], 2)\n",
    "        row1, row2 = x_test.iloc[pid1], x_test.iloc[pid2]\n",
    "        out = row1.target, row1.name, row2.target, row2.name\n",
    "        target1, name1, target2, name2 = out\n",
    "        while target1 == target2:\n",
    "            pid1, pid2 = random.sample(df.loc[group][\"index\"], 2)\n",
    "            row1, row2 = x_test.iloc[pid1], x_test.iloc[pid2]\n",
    "            target1, name1, target2, name2 = (\n",
    "                row1.target,\n",
    "                row1.name,\n",
    "                row2.target,\n",
    "                row2.name,\n",
    "            )\n",
    "        group1, group2 = row1.gender, row2.gender\n",
    "        assert target1 != target2\n",
    "        assert group1 == group2\n",
    "        f.write(f\"{target1:8s}\\t{name1}\\t{target2:8s}\\t{name2}\\n\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BASIC-GC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORY = \"BASIC-GC\"\n",
    "dir_category = \"test\"\n",
    "\n",
    "target_pair = f\"pairs/{dir_category}/pairs_{CATEGORY}.txt\"\n",
    "os.makedirs(os.path.dirname(target_pair), exist_ok=True)\n",
    "print(target_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(22)\n",
    "unique_group_total_pairs = list(combinations([\"Male\", \"Female\"], 2))\n",
    "index_list = np.random.choice(len(unique_group_total_pairs), 6000, replace=True)\n",
    "selected_group_pairs = np.array(unique_group_total_pairs)[index_list]\n",
    "\n",
    "with open(target_pair, \"w\") as f:\n",
    "    f.write(f\"{NUM_FOLDS} {NUM_PAIRS}\\n\")\n",
    "    for group in tqdm(selected_group_pairs):\n",
    "\n",
    "        def get_target_and_name(group, df=x_test):\n",
    "            row = df[df.gender == group].sample()\n",
    "            target, name = row.target.item(), row.iloc[0].name\n",
    "            return target, name\n",
    "\n",
    "        def get_pairs(group):\n",
    "            group1, group2 = group\n",
    "            target1, name1 = get_target_and_name(group1)\n",
    "            target2, name2 = get_target_and_name(group2)\n",
    "            return target1, name1, target2, name2\n",
    "\n",
    "        group1, group2 = group\n",
    "        target1, name1, target2, name2 = get_pairs(group)\n",
    "        while target1 == target2:\n",
    "            target1, name1, target2, name2 = get_pairs(group)\n",
    "        assert target1 != target2\n",
    "        assert group1 != group2\n",
    "\n",
    "        f.write(f\"{target1:8s}\\t{name1}\\t{target2:8s}\\t{name2}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face = join_face_df(DTFR, \"aihub_family\")\n",
    "valid_uuids = read_split(\"test\")\n",
    "x_test = face.loc[valid_uuids]\n",
    "x_test = x_test.reset_index().reset_index().set_index(\"uuid\")\n",
    "df = x_test.groupby([\"age_group\"]).agg(list)[['index']]\n",
    "df = df[df.index != \"above\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BASIC-A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORY = \"BASIC-A\"\n",
    "dir_category = \"test\"\n",
    "\n",
    "target_pair = f\"pairs/{dir_category}/pairs_{CATEGORY}.txt\"\n",
    "os.makedirs(os.path.dirname(target_pair), exist_ok=True)\n",
    "print(target_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(22)\n",
    "unique_age_group = [_ for _ in \"abcdefgh\"]\n",
    "index_list = np.random.choice(len(unique_age_group), 6000, replace=True)\n",
    "selected_age_group = np.array(unique_age_group)[index_list]\n",
    "\n",
    "with open(target_pair, \"w\") as f:\n",
    "    f.write(f\"{NUM_FOLDS} {NUM_PAIRS}\\n\")\n",
    "    for age_group in tqdm(selected_age_group):\n",
    "        pid1, pid2 = random.sample(df.loc[age_group][\"index\"], 2)\n",
    "        row1, row2 = x_test.iloc[pid1], x_test.iloc[pid2]\n",
    "        out = row1.target, row1.name, row2.target, row2.name\n",
    "        target1, name1, target2, name2 = out\n",
    "        while target1 == target2:\n",
    "            pid1, pid2 = random.sample(df.loc[age_group][\"index\"], 2)\n",
    "            row1, row2 = x_test.iloc[pid1], x_test.iloc[pid2]\n",
    "            target1, name1, target2, name2 = row1.target, row1.name, row2.target, row2.name\n",
    "        age_group1, age_group2 = row1.age_group, row2.age_group\n",
    "        assert target1 != target2\n",
    "        assert age_group1 == age_group2\n",
    "        f.write(f\"{target1:8s}\\t{name1}\\t{target2:8s}\\t{name2}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BASIC-AC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORY = \"BASIC-AC\"\n",
    "dir_category = \"test\"\n",
    "\n",
    "target_pair = f\"pairs/{dir_category}/pairs_{CATEGORY}.txt\"\n",
    "os.makedirs(os.path.dirname(target_pair), exist_ok=True)\n",
    "print(target_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(22)\n",
    "unique_age_group = [_ for _ in \"abcdefgh\"]\n",
    "unique_age_group_total_pairs = list(combinations(unique_age_group, 2))\n",
    "index_list = np.random.choice(len(unique_age_group_total_pairs), 6000, replace=True)\n",
    "selected_age_group_pairs = np.array(unique_age_group_total_pairs)[index_list]\n",
    "\n",
    "with open(target_pair, \"w\") as f:\n",
    "    f.write(f\"{NUM_FOLDS} {NUM_PAIRS}\\n\")\n",
    "    for age_groups in tqdm(selected_age_group_pairs):\n",
    "\n",
    "        def get_target_and_name(age_group, df=x_test):\n",
    "            row = df[df.age_group == age_group].sample()\n",
    "            target, name = row.target.item(), row.iloc[0].name\n",
    "            return target, name\n",
    "\n",
    "        def get_pairs(age_group):\n",
    "            age_group1, age_group2 = age_group\n",
    "            target1, name1 = get_target_and_name(age_group1)\n",
    "            target2, name2 = get_target_and_name(age_group2)\n",
    "            return target1, name1, target2, name2\n",
    "\n",
    "        age_group1, age_group2 = age_groups\n",
    "        target1, name1, target2, name2 = get_pairs(age_groups)\n",
    "        while target1 == target2:\n",
    "            target1, name1, target2, name2 = get_pairs(age_groups)\n",
    "        assert target1 != target2\n",
    "        assert age_group1 != age_group2\n",
    "        \n",
    "        f.write(f\"{target1:8s}\\t{name1}\\t{target2:8s}\\t{name2}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face = join_face_df(DTFR, \"aihub_family\")\n",
    "valid_uuids = read_split(\"test\")\n",
    "x_test = face.loc[valid_uuids]\n",
    "x_test = x_test.reset_index().reset_index().set_index(\"uuid\")\n",
    "df = x_test.groupby([\"family_id\"]).agg(list)[['index']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BASIC-F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORY = \"BASIC-F\"\n",
    "dir_category = \"test\"\n",
    "\n",
    "target_pair = f\"pairs/{dir_category}/pairs_{CATEGORY}.txt\"\n",
    "os.makedirs(os.path.dirname(target_pair), exist_ok=True)\n",
    "print(target_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(22)\n",
    "unique_group = x_test.family_id.unique()\n",
    "index_list = np.random.choice(len(unique_group), 6000, replace=True)\n",
    "selected_group = np.array(unique_group)[index_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(target_pair, \"w\") as f:\n",
    "    f.write(f\"{NUM_FOLDS} {NUM_PAIRS}\\n\")\n",
    "    for group in tqdm(selected_group):\n",
    "        pid1, pid2 = random.sample(df.loc[group][\"index\"], 2)\n",
    "        row1, row2 = x_test.iloc[pid1], x_test.iloc[pid2]\n",
    "        out = row1.target, row1.name, row2.target, row2.name\n",
    "        target1, name1, target2, name2 = out\n",
    "        while target1 == target2:\n",
    "            pid1, pid2 = random.sample(df.loc[group][\"index\"], 2)\n",
    "            row1, row2 = x_test.iloc[pid1], x_test.iloc[pid2]\n",
    "            target1, name1, target2, name2 = (\n",
    "                row1.target,\n",
    "                row1.name,\n",
    "                row2.target,\n",
    "                row2.name,\n",
    "            )\n",
    "        group1, group2 = row1.family_id, row2.family_id\n",
    "        assert target1 != target2\n",
    "        assert group1 == group2\n",
    "        f.write(f\"{target1:8s}\\t{name1}\\t{target2:8s}\\t{name2}\\n\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BASIC-FC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORY = \"BASIC-FC\"\n",
    "dir_category = \"test\"\n",
    "\n",
    "target_pair = f\"pairs/{dir_category}/pairs_{CATEGORY}.txt\"\n",
    "os.makedirs(os.path.dirname(target_pair), exist_ok=True)\n",
    "print(target_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(22)\n",
    "unique_group_total_pairs = list(combinations(unique_group, 2))\n",
    "index_list = np.random.choice(len(unique_group_total_pairs), 6000, replace=True)\n",
    "selected_group_pairs = np.array(unique_group_total_pairs)[index_list]\n",
    "\n",
    "with open(target_pair, \"w\") as f:\n",
    "    f.write(f\"{NUM_FOLDS} {NUM_PAIRS}\\n\")\n",
    "    for group in tqdm(selected_group_pairs):\n",
    "\n",
    "        def get_target_and_name(group, df=x_test):\n",
    "            row = df[df.family_id == group].sample()\n",
    "            target, name = row.target.item(), row.iloc[0].name\n",
    "            return target, name\n",
    "\n",
    "        def get_pairs(group):\n",
    "            group1, group2 = group\n",
    "            target1, name1 = get_target_and_name(group1)\n",
    "            target2, name2 = get_target_and_name(group2)\n",
    "            return target1, name1, target2, name2\n",
    "\n",
    "        group1, group2 = group\n",
    "        target1, name1, target2, name2 = get_pairs(group)\n",
    "        while target1 == target2:\n",
    "            target1, name1, target2, name2 = get_pairs(group)\n",
    "        assert target1 != target2\n",
    "        assert group1 != group2\n",
    "\n",
    "        f.write(f\"{target1:8s}\\t{name1}\\t{target2:8s}\\t{name2}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Under Family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fpt.data import join_face_df\n",
    "from fpt.split import read_split\n",
    "from fpt.path import DTFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FOLDS = 10\n",
    "NUM_PAIRS = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face = join_face_df(DTFR, \"aihub_family\")\n",
    "valid_uuids = read_split(\"test\")\n",
    "x_test = face.loc[valid_uuids]\n",
    "x_test = x_test[x_test.age_group != \"above\"]\n",
    "x_test = x_test.reset_index().reset_index().set_index(\"uuid\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = x_test.groupby([\"age_group\", \"family_id\", \"personal_id\"]).agg(list)[['index']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = []\n",
    "for index, group in df.groupby(['age_group', 'family_id']):\n",
    "    if len(group) < 2:\n",
    "        continue\n",
    "    for candidate in itertools.combinations(group.loc[index].index, 2):\n",
    "        pid1, pid2 = candidate\n",
    "        index_list1 = group.loc[(*index, pid1)].item()\n",
    "        index_list2 = group.loc[(*index, pid2)].item()\n",
    "        pairs = itertools.product(index_list1, index_list2)\n",
    "        for pair in pairs:\n",
    "            candidates.append(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_pairs = random.sample(candidates, 6000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FAMILY-A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORY = \"FAMILY-A\"\n",
    "dir_category = \"test\"\n",
    "\n",
    "target_pair = f\"pairs/{dir_category}/pairs_{CATEGORY}.txt\"\n",
    "os.makedirs(os.path.dirname(target_pair), exist_ok=True)\n",
    "print(target_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(target_pair, \"w\") as f:\n",
    "    f.write(f\"{NUM_FOLDS} {NUM_PAIRS}\\n\")\n",
    "    for group in tqdm(selected_pairs):\n",
    "        pid1, pid2 = group\n",
    "        row1, row2 = x_test.iloc[pid1], x_test.iloc[pid2]\n",
    "        out = row1.target, row1.name, row2.target, row2.name\n",
    "        target1, name1, target2, name2 = out\n",
    "        assert target1 != target2\n",
    "        assert row1.age_group == row2.age_group\n",
    "        assert row1.family_id == row2.family_id\n",
    "        f.write(f\"{target1:8s}\\t{name1}\\t{target2:8s}\\t{name2}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FAMILY-CA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORY = \"FAMILY-CA\"\n",
    "dir_category = \"test\"\n",
    "\n",
    "target_pair = f\"pairs/{dir_category}/pairs_{CATEGORY}.txt\"\n",
    "os.makedirs(os.path.dirname(target_pair), exist_ok=True)\n",
    "print(target_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = x_test.groupby([\"age_group\", \"family_id\"]).agg(list)[['index']]\n",
    "candidates = []\n",
    "\n",
    "np.random.seed(22)\n",
    "random.seed(22)\n",
    "\n",
    "for index, group in df.groupby(\"age_group\"):\n",
    "    all_afid = list(group.index)\n",
    "    for candidate in itertools.combinations(all_afid, 2):\n",
    "        candidates.append(candidate)\n",
    "selected_candidates = random.sample(candidates, 6000)\n",
    "with open(target_pair, \"w\") as f:\n",
    "    f.write(f\"{NUM_FOLDS} {NUM_PAIRS}\\n\")\n",
    "    for dfidx1, dfidx2 in tqdm(selected_candidates):\n",
    "        idx1 = random.sample(df.loc[dfidx1].item(), 1)\n",
    "        idx2 = random.sample(df.loc[dfidx2].item(), 1)\n",
    "        row1 = x_test.iloc[idx1]\n",
    "        row2 = x_test.iloc[idx2]\n",
    "        target1, name1 = row1.target.item(), row1.index.item()\n",
    "        target2, name2 = row2.target.item(), row2.index.item()\n",
    "        assert target1 != target2\n",
    "        assert row1.age_group.item() == row2.age_group.item()\n",
    "        assert row1.family_id.item() != row2.family_id.item()\n",
    "        f.write(f\"{target1:8s}\\t{name1}\\t{target2:8s}\\t{name2}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = x_test.groupby([\"gender\", \"family_id\", \"personal_id\"]).agg(list)[['index']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = []\n",
    "for index, group in df.groupby(['gender', 'family_id']):\n",
    "    if len(group) < 2:\n",
    "        continue\n",
    "    for candidate in itertools.combinations(group.loc[index].index, 2):\n",
    "        pid1, pid2 = candidate\n",
    "        index_list1 = group.loc[(*index, pid1)].item()\n",
    "        index_list2 = group.loc[(*index, pid2)].item()\n",
    "        pairs = itertools.product(index_list1, index_list2)\n",
    "        for pair in pairs:\n",
    "            candidates.append(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_pairs = random.sample(candidates, 6000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FAMILY-G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORY = \"FAMILY-G\"\n",
    "dir_category = \"test\"\n",
    "\n",
    "target_pair = f\"pairs/{dir_category}/pairs_{CATEGORY}.txt\"\n",
    "os.makedirs(os.path.dirname(target_pair), exist_ok=True)\n",
    "print(target_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(target_pair, \"w\") as f:\n",
    "    f.write(f\"{NUM_FOLDS} {NUM_PAIRS}\\n\")\n",
    "    for group in tqdm(selected_pairs):\n",
    "        pid1, pid2 = group\n",
    "        row1, row2 = x_test.iloc[pid1], x_test.iloc[pid2]\n",
    "        out = row1.target, row1.name, row2.target, row2.name\n",
    "        target1, name1, target2, name2 = out\n",
    "        assert target1 != target2\n",
    "        assert row1.gender == row2.gender\n",
    "        assert row1.family_id == row2.family_id\n",
    "        f.write(f\"{target1:8s}\\t{name1}\\t{target2:8s}\\t{name2}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FAMILY-CG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORY = \"FAMILY-CG\"\n",
    "dir_category = \"test\"\n",
    "\n",
    "target_pair = f\"pairs/{dir_category}/pairs_{CATEGORY}.txt\"\n",
    "os.makedirs(os.path.dirname(target_pair), exist_ok=True)\n",
    "print(target_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = x_test.groupby([\"gender\", \"family_id\"]).agg(list)[['index']]\n",
    "candidates = []\n",
    "\n",
    "np.random.seed(22)\n",
    "random.seed(22)\n",
    "\n",
    "for index, group in df.groupby(\"gender\"):\n",
    "    all_gfid = list(group.index)\n",
    "    for candidate in itertools.combinations(all_gfid, 2):\n",
    "        candidates.append(candidate)\n",
    "selected_candidates = random.sample(candidates, 6000)\n",
    "with open(target_pair, \"w\") as f:\n",
    "    f.write(f\"{NUM_FOLDS} {NUM_PAIRS}\\n\")\n",
    "    for dfidx1, dfidx2 in tqdm(selected_candidates):\n",
    "        idx1 = random.sample(df.loc[dfidx1].item(), 1)\n",
    "        idx2 = random.sample(df.loc[dfidx2].item(), 1)\n",
    "        row1 = x_test.iloc[idx1]\n",
    "        row2 = x_test.iloc[idx2]\n",
    "        target1, name1 = row1.target.item(), row1.index.item()\n",
    "        target2, name2 = row2.target.item(), row2.index.item()\n",
    "        assert target1 != target2\n",
    "        assert row1.gender.item() == row2.gender.item()\n",
    "        assert row1.family_id.item() != row2.family_id.item()\n",
    "        f.write(f\"{target1:8s}\\t{name1}\\t{target2:8s}\\t{name2}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age/Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = x_test.groupby([\"gender\", \"age_group\", \"family_id\", \"personal_id\"]).agg(list)[['index']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = []\n",
    "for index, group in df.groupby(['gender', \"age_group\", 'family_id']):\n",
    "    if len(group) < 2:\n",
    "        continue\n",
    "    for candidate in itertools.combinations(group.loc[index].index, 2):\n",
    "        pid1, pid2 = candidate\n",
    "        index_list1 = group.loc[(*index, pid1)].item()\n",
    "        index_list2 = group.loc[(*index, pid2)].item()\n",
    "        pairs = itertools.product(index_list1, index_list2)\n",
    "        for pair in pairs:\n",
    "            candidates.append(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_pairs = random.sample(candidates, 6000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FAMILY-AG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORY = \"FAMILY-AG\"\n",
    "dir_category = \"test\"\n",
    "\n",
    "target_pair = f\"pairs/{dir_category}/pairs_{CATEGORY}.txt\"\n",
    "os.makedirs(os.path.dirname(target_pair), exist_ok=True)\n",
    "print(target_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(target_pair, \"w\") as f:\n",
    "    f.write(f\"{NUM_FOLDS} {NUM_PAIRS}\\n\")\n",
    "    for group in tqdm(selected_pairs):\n",
    "        pid1, pid2 = group\n",
    "        row1, row2 = x_test.iloc[pid1], x_test.iloc[pid2]\n",
    "        out = row1.target, row1.name, row2.target, row2.name\n",
    "        target1, name1, target2, name2 = out\n",
    "        assert target1 != target2\n",
    "        assert row1.gender == row2.gender\n",
    "        assert row1.age_group == row2.age_group\n",
    "        assert row1.family_id == row2.family_id\n",
    "        f.write(f\"{target1:8s}\\t{name1}\\t{target2:8s}\\t{name2}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FAMILY-CAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORY = \"FAMILY-CAG\"\n",
    "dir_category = \"test\"\n",
    "\n",
    "target_pair = f\"pairs/{dir_category}/pairs_{CATEGORY}.txt\"\n",
    "os.makedirs(os.path.dirname(target_pair), exist_ok=True)\n",
    "print(target_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = x_test.groupby([\"gender\", \"age_group\", \"family_id\"]).agg(list)[[\"index\"]]\n",
    "candidates = []\n",
    "\n",
    "np.random.seed(22)\n",
    "random.seed(22)\n",
    "\n",
    "for index, group in df.groupby([\"gender\", \"age_group\"]):\n",
    "    all_gfid = list(group.index)\n",
    "    for candidate in itertools.combinations(all_gfid, 2):\n",
    "        candidates.append(candidate)\n",
    "selected_candidates = random.sample(candidates, 6000)\n",
    "with open(target_pair, \"w\") as f:\n",
    "    f.write(f\"{NUM_FOLDS} {NUM_PAIRS}\\n\")\n",
    "    for dfidx1, dfidx2 in tqdm(selected_candidates):\n",
    "        idx1 = random.sample(df.loc[dfidx1].item(), 1)\n",
    "        idx2 = random.sample(df.loc[dfidx2].item(), 1)\n",
    "        row1 = x_test.iloc[idx1]\n",
    "        row2 = x_test.iloc[idx2]\n",
    "        target1, name1 = row1.target.item(), row1.index.item()\n",
    "        target2, name2 = row2.target.item(), row2.index.item()\n",
    "        assert target1 != target2\n",
    "        assert row1.gender.item() == row2.gender.item()\n",
    "        assert row1.age_group.item() == row2.age_group.item()\n",
    "        assert row1.family_id.item() != row2.family_id.item()\n",
    "        f.write(f\"{target1:8s}\\t{name1}\\t{target2:8s}\\t{name2}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd \"/home/jupyter/family-photo-tree\"\n",
    "%pwd\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.modules.distance import PairwiseDistance\n",
    "from fpt.path import DATA\n",
    "from fpt.model import Model\n",
    "from fpt.config import cfg\n",
    "from fpt.dataset import AIHubDataset\n",
    "from fpt.logger import initialize_wandb\n",
    "from fpt.utils import log_verification_output\n",
    "from fpt.transform import aihub_valid_transforms\n",
    "from facenet.validate_aihub import validate_aihub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logger\n",
    "wandb_logger = initialize_wandb(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_task = \"CASE1C\"\n",
    "checkpoint = \"230529_0140\"\n",
    "best_distance = 28.465\n",
    "cfg.project_name = \"log_test_validation\"\n",
    "\n",
    "# dataloader\n",
    "aihub_pairs_case1c_dataset = AIHubDataset(\n",
    "    dir=DATA / \"face-image/test_aihub_family\",\n",
    "    pairs_path=DATA / f\"pairs/test/pairs_{validate_task.upper()}.txt\",\n",
    "    transform=aihub_valid_transforms,\n",
    ")\n",
    "test_loader = DataLoader(aihub_pairs_case1c_dataset, batch_size=32)\n",
    "\n",
    "# model\n",
    "model = Model(cfg)\n",
    "model_path = f\"/home/jongphago/family-photo-tree/work_dirs/aihub_r50_onegpu/{checkpoint}_ArcFace/model.pt\"\n",
    "model.load_embedding(path=model_path)\n",
    "\n",
    "# distance_metric\n",
    "l2_distance = PairwiseDistance(p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = 0\n",
    "for a, b, label in tqdm(test_loader):\n",
    "    output_a = model.embedding(a.cuda())\n",
    "    output_b = model.embedding(b.cuda())\n",
    "    distance = l2_distance.forward(output_a, output_b)  # Euclidean distance\n",
    "    result = torch.eq(distance.cpu().detach() < best_distance, label)\n",
    "    out += result.sum().detach()\n",
    "\n",
    "print(f\"{out / len(test_loader.dataset):4.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_output = validate_aihub(\n",
    "    model.embedding, test_loader, \"r50\", 1, task=validate_task\n",
    ")\n",
    "log_verification_output(validate_output, wandb_logger, validate_task.capitalize(), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
