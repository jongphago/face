{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from fpt.data import join_face_df\n",
    "from fpt.split import read_split\n",
    "from fpt.path import DTFR, UTIL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face = join_face_df(DTFR, \"aihub_family\")  # 16.1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_CATEGORY = \"train\"\n",
    "valid_uuids = read_split(TASK_CATEGORY)\n",
    "x_valid = face.loc[valid_uuids]\n",
    "x_valid = x_valid.reset_index().reset_index().set_index(\"uuid\")\n",
    "x_valid.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample group\n",
    "# x_valid.groupby('target').index.apply(list).to_frame().head()\n",
    "# x_valid.groupby(['family_id', 'personal_id', 'category']).index.apply(list).to_frame().head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(22)\n",
    "NUM_FOLDS = 10\n",
    "NUM_PAIRS = 300\n",
    "CATEGORY = \"Age\"\n",
    "target_pair = f\"pairs/{TASK_CATEGORY}/pairs_{CATEGORY}.txt\"\n",
    "os.makedirs(os.path.dirname(target_pair), exist_ok=True)\n",
    "\n",
    "is_family = x_valid.category == CATEGORY\n",
    "family_valid = x_valid[is_family]\n",
    "idx_family_valid = family_valid.groupby(\"target\").index.apply(list).to_frame()\n",
    "\n",
    "with open(target_pair, \"w\") as f:\n",
    "    f.write(f\"{NUM_FOLDS} {NUM_PAIRS}\\n\")\n",
    "    for n in range(NUM_FOLDS):\n",
    "        # matched\n",
    "        matched_sample = idx_family_valid.sample(\n",
    "            n=300, replace=False, random_state=n\n",
    "        ).sort_values(\"target\")\n",
    "        for key, value in matched_sample.iterrows():\n",
    "            idxs = value.loc[\"index\"]\n",
    "            selected = np.random.choice(idxs, size=2, replace=False)\n",
    "            f.write(f\"{key:8s}\\t{valid_uuids[selected[0]]}\\t{valid_uuids[selected[1]]}\")\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "        # mismatched\n",
    "        for i in range(300):\n",
    "            mismatched_sample = idx_family_valid.sample(\n",
    "                n=2, replace=False, random_state=n * 1000 + i\n",
    "            ).sort_values(\"target\")\n",
    "            sampled = [\n",
    "                [key, np.random.choice(value.loc[\"index\"], replace=False)]\n",
    "                for key, value in mismatched_sample.iterrows()\n",
    "            ]\n",
    "            target_a, idx_a, target_b, idx_b = np.array(sampled).flatten().tolist()\n",
    "            uuid_a, uuid_b = valid_uuids[int(idx_a)], valid_uuids[int(idx_b)]\n",
    "            f.write(f\"{target_a:<8}\\t{uuid_a}\\t{target_b:<8}\\t{uuid_b}\")\n",
    "            f.write(\"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get New Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fpt.data import join_face_df\n",
    "from fpt.split import read_split\n",
    "from fpt.path import DTFR\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face = join_face_df(DTFR, \"aihub_family\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_CATEGORY = \"valid\"\n",
    "valid_uuids = read_split(TASK_CATEGORY)\n",
    "x_valid = face.loc[valid_uuids]\n",
    "x_valid = x_valid.reset_index().reset_index().set_index(\"uuid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = x_valid.groupby([\"family_id\", \"age_group\", \"gender\", \"personal_id\"]).agg(list)[[\"index\"]]\n",
    "\n",
    "# 인덱스 쌍을 저장할 빈 리스트를 생성합니다.\n",
    "index_pairs = []\n",
    "\n",
    "# 각 그룹에 대해 인덱스 쌍을 생성합니다.\n",
    "for _, group in df.groupby([\"family_id\", \"age_group\", \"gender\"]):\n",
    "    index_list = group[\"index\"].tolist()\n",
    "\n",
    "    # 그룹의 인덱스 리스트에 두 개 이상의 원소가 있는 경우에만 조합을 생성합니다.\n",
    "    if len(index_list) >= 2:\n",
    "        for candidate in itertools.combinations(index_list, 2):\n",
    "            for pair in itertools.product(*candidate):\n",
    "                index_pairs.append([*group.index[0][:3], pair])\n",
    "\n",
    "# 인덱스 쌍을 출력합니다.\n",
    "pd.DataFrame(index_pairs, columns=[\"family_id\", \"age_group\", \"gender\", \"pairs\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CASE1: 가족 관계에 있는 얼굴쌍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from fpt.data import join_face_df\n",
    "from fpt.split import read_split\n",
    "from fpt.path import DTFR\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face = join_face_df(DTFR, \"aihub_family\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(22)\n",
    "NUM_FOLDS = 10\n",
    "NUM_PAIRS = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORY = \"CASE1\"\n",
    "TASK_CATEGORY = \"test\"\n",
    "target_pair = f\"pairs/{TASK_CATEGORY}/pairs_{CATEGORY}.txt\"\n",
    "os.makedirs(os.path.dirname(target_pair), exist_ok=True)\n",
    "print(target_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_uuids = read_split(TASK_CATEGORY)\n",
    "x_valid = face.loc[valid_uuids]\n",
    "x_valid = x_valid.reset_index().reset_index().set_index(\"uuid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = x_valid.groupby([\"family_id\", \"personal_id\"]).agg(list)[[\"index\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 그룹에 대해 인덱스 쌍을 생성합니다.\n",
    "total_matched_list = []\n",
    "for index, value in df.itertuples():\n",
    "    for candidate in itertools.combinations(value, 2):\n",
    "        total_matched_list.append([index[0], candidate])\n",
    "total_matched_pairs = pd.DataFrame(total_matched_list, columns=[\"family_id\", \"pairs\"])\n",
    "selected_matched_pairs = total_matched_pairs.sample(\n",
    "    n=3000, replace=False, random_state=22\n",
    ")\n",
    "\n",
    "# 인덱스 쌍을 저장할 빈 리스트를 생성합니다.\n",
    "total_mismatched_list = []\n",
    "\n",
    "# 각 그룹에 대해 인덱스 쌍을 생성합니다.\n",
    "for _, group in df.groupby([\"family_id\"]):\n",
    "    index_list = group[\"index\"].tolist()\n",
    "\n",
    "    # 그룹의 인덱스 리스트에 두 개 이상의 원소가 있는 경우에만 조합을 생성합니다.\n",
    "    if len(index_list) >= 2:\n",
    "        for candidate in itertools.combinations(index_list, 2):\n",
    "            for pair in itertools.product(*candidate):\n",
    "                total_mismatched_list.append([*group.index[0][:1], pair])\n",
    "\n",
    "# 인덱스 쌍을 출력합니다.\n",
    "total_mismatched_pairs = pd.DataFrame(\n",
    "    total_mismatched_list, columns=[\"family_id\", \"pairs\"]\n",
    ")\n",
    "selected_mismatched_pairs = total_mismatched_pairs.sample(\n",
    "    n=3000, replace=False, random_state=22\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_matched = [\n",
    "    group\n",
    "    for _, group in selected_matched_pairs.groupby(\n",
    "        np.arange(len(selected_matched_pairs)) // NUM_PAIRS\n",
    "    )\n",
    "]\n",
    "dfs_mismatched = [\n",
    "    group\n",
    "    for _, group in selected_mismatched_pairs.groupby(\n",
    "        np.arange(len(selected_mismatched_pairs)) // NUM_PAIRS\n",
    "    )\n",
    "]\n",
    "\n",
    "with open(target_pair, \"w\") as f:\n",
    "    f.write(f\"{NUM_FOLDS} {NUM_PAIRS}\\n\")\n",
    "    for df_matched, df_mismatched in zip(dfs_matched, dfs_mismatched):\n",
    "        for row in df_matched.itertuples():\n",
    "            idx1, idx2 = row.pairs\n",
    "            target = x_valid.iloc[idx1].target\n",
    "            assert target == x_valid.iloc[idx2].target\n",
    "            name1 = x_valid.iloc[idx1].name\n",
    "            name2 = x_valid.iloc[idx2].name\n",
    "            f.write(f\"{target:8s}\\t{name1}\\t{name2}\\n\")\n",
    "\n",
    "        for row in df_mismatched.itertuples():\n",
    "            idx1, idx2 = row.pairs\n",
    "            target1 = x_valid.iloc[idx1].target\n",
    "            target2 = x_valid.iloc[idx2].target\n",
    "            assert x_valid.iloc[idx1].family_id == x_valid.iloc[idx2].family_id\n",
    "            assert target1 != target2\n",
    "            name1 = x_valid.iloc[idx1].name\n",
    "            name2 = x_valid.iloc[idx2].name\n",
    "            f.write(f\"{target1:8s}\\t{name1}\\t{target2:8s}\\t{name2}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
