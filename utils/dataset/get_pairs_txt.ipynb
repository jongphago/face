{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face = join_face_df(DTFR, \"aihub_family\")  # 16.1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from fpt.data import join_face_df\n",
    "from fpt.split import read_split\n",
    "from fpt.path import DTFR, UTIL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_CATEGORY = \"train\"\n",
    "valid_uuids = read_split(TASK_CATEGORY)\n",
    "x_valid = face.loc[valid_uuids]\n",
    "x_valid = x_valid.reset_index().reset_index().set_index(\"uuid\")\n",
    "x_valid.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample group\n",
    "# x_valid.groupby('target').index.apply(list).to_frame().head()\n",
    "# x_valid.groupby(['family_id', 'personal_id', 'category']).index.apply(list).to_frame().head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(22)\n",
    "NUM_FOLDS = 10\n",
    "NUM_PAIRS = 300\n",
    "CATEGORY = \"Age\"\n",
    "target_pair = f\"pairs/{TASK_CATEGORY}/pairs_{CATEGORY}.txt\"\n",
    "os.makedirs(os.path.dirname(target_pair), exist_ok=True)\n",
    "\n",
    "is_family = x_valid.category == CATEGORY\n",
    "family_valid = x_valid[is_family]\n",
    "idx_family_valid = family_valid.groupby(\"target\").index.apply(list).to_frame()\n",
    "\n",
    "with open(target_pair, \"w\") as f:\n",
    "    f.write(f\"{NUM_FOLDS} {NUM_PAIRS}\\n\")\n",
    "    for n in range(NUM_FOLDS):\n",
    "        # matched\n",
    "        matched_sample = idx_family_valid.sample(\n",
    "            n=300, replace=False, random_state=n\n",
    "        ).sort_values(\"target\")\n",
    "        for key, value in matched_sample.iterrows():\n",
    "            idxs = value.loc[\"index\"]\n",
    "            selected = np.random.choice(idxs, size=2, replace=False)\n",
    "            f.write(f\"{key:8s}\\t{valid_uuids[selected[0]]}\\t{valid_uuids[selected[1]]}\")\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "        # mismatched\n",
    "        for i in range(300):\n",
    "            mismatched_sample = idx_family_valid.sample(\n",
    "                n=2, replace=False, random_state=n * 1000 + i\n",
    "            ).sort_values(\"target\")\n",
    "            sampled = [\n",
    "                [key, np.random.choice(value.loc[\"index\"], replace=False)]\n",
    "                for key, value in mismatched_sample.iterrows()\n",
    "            ]\n",
    "            target_a, idx_a, target_b, idx_b = np.array(sampled).flatten().tolist()\n",
    "            uuid_a, uuid_b = valid_uuids[int(idx_a)], valid_uuids[int(idx_b)]\n",
    "            f.write(f\"{target_a:<8}\\t{uuid_a}\\t{target_b:<8}\\t{uuid_b}\")\n",
    "            f.write(\"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get New Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fpt.data import join_face_df\n",
    "from fpt.split import read_split\n",
    "from fpt.path import DTFR\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face = join_face_df(DTFR, \"aihub_family\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_CATEGORY = \"valid\"\n",
    "valid_uuids = read_split(TASK_CATEGORY)\n",
    "x_valid = face.loc[valid_uuids]\n",
    "x_valid = x_valid.reset_index().reset_index().set_index(\"uuid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = x_valid.groupby([\"family_id\", \"age_group\", \"gender\", \"personal_id\"]).agg(list)[\n",
    "    [\"index\"]\n",
    "]\n",
    "\n",
    "# 인덱스 쌍을 저장할 빈 리스트를 생성합니다.\n",
    "index_pairs = []\n",
    "\n",
    "# 각 그룹에 대해 인덱스 쌍을 생성합니다.\n",
    "for _, group in df.groupby([\"family_id\", \"age_group\", \"gender\"]):\n",
    "    index_list = group[\"index\"].tolist()\n",
    "\n",
    "    # 그룹의 인덱스 리스트에 두 개 이상의 원소가 있는 경우에만 조합을 생성합니다.\n",
    "    if len(index_list) >= 2:\n",
    "        for candidate in itertools.combinations(index_list, 2):\n",
    "            for pair in itertools.product(*candidate):\n",
    "                index_pairs.append([*group.index[0][:3], pair])\n",
    "\n",
    "# 인덱스 쌍을 출력합니다.\n",
    "pd.DataFrame(index_pairs, columns=[\"family_id\", \"age_group\", \"gender\", \"pairs\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CASE1: 가족 관계에 있는 얼굴쌍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from fpt.data import join_face_df\n",
    "from fpt.split import read_split\n",
    "from fpt.path import DTFR\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face = join_face_df(DTFR, \"aihub_family\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(22)\n",
    "NUM_FOLDS = 10\n",
    "NUM_PAIRS = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORY = \"CASE1\"\n",
    "TASK_CATEGORY = \"test\"\n",
    "target_pair = f\"pairs/{TASK_CATEGORY}/pairs_{CATEGORY}.txt\"\n",
    "os.makedirs(os.path.dirname(target_pair), exist_ok=True)\n",
    "print(target_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_uuids = read_split(TASK_CATEGORY)\n",
    "x_valid = face.loc[valid_uuids]\n",
    "x_valid = x_valid.reset_index().reset_index().set_index(\"uuid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = x_valid.groupby([\"family_id\", \"personal_id\"]).agg(list)[[\"index\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 그룹에 대해 인덱스 쌍을 생성합니다.\n",
    "total_matched_list = []\n",
    "for index, value in df.itertuples():\n",
    "    for candidate in itertools.combinations(value, 2):\n",
    "        total_matched_list.append([index[0], candidate])\n",
    "total_matched_pairs = pd.DataFrame(total_matched_list, columns=[\"family_id\", \"pairs\"])\n",
    "selected_matched_pairs = total_matched_pairs.sample(\n",
    "    n=3000, replace=False, random_state=22\n",
    ")\n",
    "\n",
    "# 인덱스 쌍을 저장할 빈 리스트를 생성합니다.\n",
    "total_mismatched_list = []\n",
    "\n",
    "# 각 그룹에 대해 인덱스 쌍을 생성합니다.\n",
    "for _, group in df.groupby([\"family_id\"]):\n",
    "    index_list = group[\"index\"].tolist()\n",
    "\n",
    "    # 그룹의 인덱스 리스트에 두 개 이상의 원소가 있는 경우에만 조합을 생성합니다.\n",
    "    if len(index_list) >= 2:\n",
    "        for candidate in itertools.combinations(index_list, 2):\n",
    "            for pair in itertools.product(*candidate):\n",
    "                total_mismatched_list.append([*group.index[0][:1], pair])\n",
    "\n",
    "# 인덱스 쌍을 출력합니다.\n",
    "total_mismatched_pairs = pd.DataFrame(\n",
    "    total_mismatched_list, columns=[\"family_id\", \"pairs\"]\n",
    ")\n",
    "selected_mismatched_pairs = total_mismatched_pairs.sample(\n",
    "    n=3000, replace=False, random_state=22\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_matched = [\n",
    "    group\n",
    "    for _, group in selected_matched_pairs.groupby(\n",
    "        np.arange(len(selected_matched_pairs)) // NUM_PAIRS\n",
    "    )\n",
    "]\n",
    "dfs_mismatched = [\n",
    "    group\n",
    "    for _, group in selected_mismatched_pairs.groupby(\n",
    "        np.arange(len(selected_mismatched_pairs)) // NUM_PAIRS\n",
    "    )\n",
    "]\n",
    "\n",
    "with open(target_pair, \"w\") as f:\n",
    "    f.write(f\"{NUM_FOLDS} {NUM_PAIRS}\\n\")\n",
    "    for df_matched, df_mismatched in zip(dfs_matched, dfs_mismatched):\n",
    "        for row in df_matched.itertuples():\n",
    "            idx1, idx2 = row.pairs\n",
    "            target = x_valid.iloc[idx1].target\n",
    "            assert target == x_valid.iloc[idx2].target\n",
    "            name1 = x_valid.iloc[idx1].name\n",
    "            name2 = x_valid.iloc[idx2].name\n",
    "            f.write(f\"{target:8s}\\t{name1}\\t{name2}\\n\")\n",
    "\n",
    "        for row in df_mismatched.itertuples():\n",
    "            idx1, idx2 = row.pairs\n",
    "            target1 = x_valid.iloc[idx1].target\n",
    "            target2 = x_valid.iloc[idx2].target\n",
    "            assert x_valid.iloc[idx1].family_id == x_valid.iloc[idx2].family_id\n",
    "            assert target1 != target2\n",
    "            name1 = x_valid.iloc[idx1].name\n",
    "            name2 = x_valid.iloc[idx2].name\n",
    "            f.write(f\"{target1:8s}\\t{name1}\\t{target2:8s}\\t{name2}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CASE1C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORY = \"CASE1C\"\n",
    "DIR_CATEGORY = \"test\"\n",
    "TASK_CATEGORY = \"test\"\n",
    "\n",
    "target_pair = f\"pairs/{DIR_CATEGORY}/pairs_{CATEGORY}.txt\"\n",
    "os.makedirs(os.path.dirname(target_pair), exist_ok=True)\n",
    "print(target_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(22)\n",
    "unique_family_id = x_valid.family_id.unique()\n",
    "unique_family_id_total_pairs = list(combinations(unique_family_id, 2))\n",
    "index_list = np.random.choice(len(unique_family_id_total_pairs), 6000, replace=True)\n",
    "selected_family_pairs = np.array(unique_family_id_total_pairs)[index_list]\n",
    "with open(target_pair, \"w\") as f:\n",
    "    f.write(f\"{NUM_FOLDS} {NUM_PAIRS}\\n\")\n",
    "    for fids in selected_family_pairs:\n",
    "\n",
    "        def get_target_and_name(family_id, df=x_valid):\n",
    "            row = df[df.family_id == family_id].sample()\n",
    "            target, name = row.target.item(), row.iloc[0].name\n",
    "            return target, name\n",
    "\n",
    "        fid1, fid2 = fids\n",
    "        target1, name1 = get_target_and_name(fid1)\n",
    "        target2, name2 = get_target_and_name(fid2)\n",
    "        f.write(f\"{target1:8s}\\t{name1}\\t{target2:8s}\\t{name2}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pairs/test/pairs_CASE1C.txt`\n",
    "```markdown\n",
    "10 300\n",
    "F0836-M \t7649eabb-da97-4bd6-9e66-adeee88c69cc\tF0900-D \ted80801a-5c34-4a6a-bb8f-20deb0ca9ca4\n",
    "F0891-S \t749c628a-cb31-4179-9b26-19ccfa5f6018\tF0895-D \te3cfbe54-71d4-461c-861e-bb058ed594c9\n",
    "F0804-D \t9d5d61c5-f8d9-485c-a912-f156e27ebc3f\tF0867-S3\tf94cd228-762b-4e0c-a3ce-a50eff6cb049\n",
    "F0873-M \t6dc0dfb0-52c6-40ee-9f44-fb7a546560fc\tF0889-D \t326b1e97-d796-4af9-982d-7ec73bff9c10\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CASE2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from fpt.data import join_face_df\n",
    "from fpt.split import read_split\n",
    "from fpt.path import DTFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face = join_face_df(DTFR, \"aihub_family\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FOLDS = 10\n",
    "NUM_PAIRS = 300\n",
    "CATEGORY = \"CASE2\"\n",
    "DIR_CATEGORY = \"temp\"\n",
    "TASK_CATEGORY = \"test\"\n",
    "\n",
    "target_pair = f\"pairs/{DIR_CATEGORY}/pairs_{CATEGORY}.txt\"\n",
    "os.makedirs(os.path.dirname(target_pair), exist_ok=True)\n",
    "print(target_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_uuids = read_split(TASK_CATEGORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid = face.loc[valid_uuids]\n",
    "x_valid = x_valid.reset_index().reset_index().set_index(\"uuid\")\n",
    "df = x_valid.groupby([\"target\", \"age_group\"]).agg(list)[['index']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_same_age_list = []  # 52310\n",
    "for index, value in df.itertuples():\n",
    "    for candidate in itertools.combinations(value, 2):\n",
    "        total_same_age_list.append([*index, candidate])\n",
    "        \n",
    "total_same_age_pairs = pd.DataFrame(total_same_age_list, columns=[\"family_id\", \"age_group\", \"pairs\"])\n",
    "selected_same_age_pairs = total_same_age_pairs.sample(\n",
    "    n=6000, replace=False, random_state=22\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAME personal_id & SAME age_group\n",
    "with open(target_pair, \"w\") as f:\n",
    "    f.write(f\"{NUM_FOLDS} {NUM_PAIRS}\\n\")\n",
    "    for row in selected_same_age_pairs.itertuples():\n",
    "        idx1, idx2 = row.pairs\n",
    "        target = x_valid.iloc[idx1].target\n",
    "        age_group = x_valid.iloc[idx1].age_group\n",
    "        assert age_group == x_valid.iloc[idx2].age_group\n",
    "        name1 = x_valid.iloc[idx1].name\n",
    "        name2 = x_valid.iloc[idx2].name\n",
    "        f.write(f\"{target:8s}\\t{name1}\\t{name2}\\n\")\n",
    "        # break\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CASE2C:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FOLDS = 10\n",
    "NUM_PAIRS = 300\n",
    "CATEGORY = \"CASE2C\"\n",
    "DIR_CATEGORY = \"temp\"\n",
    "TASK_CATEGORY = \"test\"\n",
    "\n",
    "target_pair = f\"pairs/{DIR_CATEGORY}/pairs_{CATEGORY}.txt\"\n",
    "os.makedirs(os.path.dirname(target_pair), exist_ok=True)\n",
    "print(target_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인덱스 쌍을 저장할 빈 리스트를 생성합니다.\n",
    "total_mismatched_list = []\n",
    "\n",
    "# 각 그룹에 대해 인덱스 쌍을 생성합니다.\n",
    "for _, group in df.groupby([\"target\"]):\n",
    "    index_list = group[\"index\"].tolist()\n",
    "    # 그룹의 인덱스 리스트에 두 개 이상의 원소가 있는 경우에만 조합을 생성합니다.\n",
    "    if len(index_list) >= 2:\n",
    "        for candidate in itertools.combinations(index_list, 2):\n",
    "            for pair in itertools.product(*candidate):\n",
    "                total_mismatched_list.append([*group.index[0][:1], pair])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인덱스 쌍을 출력합니다.\n",
    "total_mismatched_pairs = pd.DataFrame(\n",
    "    total_mismatched_list, columns=[\"target\", \"pairs\"]\n",
    ")\n",
    "selected_mismatched_pairs = total_mismatched_pairs.sample(\n",
    "    n=6000, replace=False, random_state=22\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(target_pair, \"w\") as f:\n",
    "    f.write(f\"{NUM_FOLDS} {NUM_PAIRS}\\n\")\n",
    "    for row in selected_mismatched_pairs.itertuples():\n",
    "        idx1, idx2 = row.pairs\n",
    "        target1 = x_valid.iloc[idx1].target\n",
    "        target2 = x_valid.iloc[idx2].target\n",
    "        assert x_valid.iloc[idx1].age_group != x_valid.iloc[idx2].age_group\n",
    "        assert target1 == target2\n",
    "        name1 = x_valid.iloc[idx1].name\n",
    "        name2 = x_valid.iloc[idx2].name\n",
    "        f.write(f\"{target1:8s}\\t{name1}\\t{name2}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fpt.data import join_face_df\n",
    "from fpt.split import read_split\n",
    "from fpt.path import DTFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FOLDS = 10\n",
    "NUM_PAIRS = 300"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face = join_face_df(DTFR, \"aihub_family\")\n",
    "valid_uuids = read_split(\"test\")\n",
    "x_test = face.loc[valid_uuids]\n",
    "x_test = x_test.reset_index().reset_index().set_index(\"uuid\")\n",
    "df = x_test.groupby([\"gender\"]).agg(list)[['index']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BASIC-G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORY = \"BASIC-G\"\n",
    "dir_category = \"test\"\n",
    "\n",
    "target_pair = f\"pairs/{dir_category}/pairs_{CATEGORY}.txt\"\n",
    "os.makedirs(os.path.dirname(target_pair), exist_ok=True)\n",
    "print(target_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(22)\n",
    "unique_group = [\"Male\", \"Female\"]\n",
    "index_list = np.random.choice(len(unique_group), 6000, replace=True)\n",
    "selected_group = np.array(unique_group)[index_list]\n",
    "\n",
    "with open(target_pair, \"w\") as f:\n",
    "    f.write(f\"{NUM_FOLDS} {NUM_PAIRS}\\n\")\n",
    "    for group in tqdm(selected_group):\n",
    "        pid1, pid2 = random.sample(df.loc[group][\"index\"], 2)\n",
    "        row1, row2 = x_test.iloc[pid1], x_test.iloc[pid2]\n",
    "        out = row1.target, row1.name, row2.target, row2.name\n",
    "        target1, name1, target2, name2 = out\n",
    "        while target1 == target2:\n",
    "            pid1, pid2 = random.sample(df.loc[group][\"index\"], 2)\n",
    "            row1, row2 = x_test.iloc[pid1], x_test.iloc[pid2]\n",
    "            target1, name1, target2, name2 = (\n",
    "                row1.target,\n",
    "                row1.name,\n",
    "                row2.target,\n",
    "                row2.name,\n",
    "            )\n",
    "        group1, group2 = row1.gender, row2.gender\n",
    "        assert target1 != target2\n",
    "        assert group1 == group2\n",
    "        f.write(f\"{target1:8s}\\t{name1}\\t{target2:8s}\\t{name2}\\n\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BASIC-GC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORY = \"BASIC-GC\"\n",
    "dir_category = \"test\"\n",
    "\n",
    "target_pair = f\"pairs/{dir_category}/pairs_{CATEGORY}.txt\"\n",
    "os.makedirs(os.path.dirname(target_pair), exist_ok=True)\n",
    "print(target_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(22)\n",
    "unique_group_total_pairs = list(combinations([\"Male\", \"Female\"], 2))\n",
    "index_list = np.random.choice(len(unique_group_total_pairs), 6000, replace=True)\n",
    "selected_group_pairs = np.array(unique_group_total_pairs)[index_list]\n",
    "\n",
    "with open(target_pair, \"w\") as f:\n",
    "    f.write(f\"{NUM_FOLDS} {NUM_PAIRS}\\n\")\n",
    "    for group in tqdm(selected_group_pairs):\n",
    "\n",
    "        def get_target_and_name(group, df=x_test):\n",
    "            row = df[df.gender == group].sample()\n",
    "            target, name = row.target.item(), row.iloc[0].name\n",
    "            return target, name\n",
    "\n",
    "        def get_pairs(group):\n",
    "            group1, group2 = group\n",
    "            target1, name1 = get_target_and_name(group1)\n",
    "            target2, name2 = get_target_and_name(group2)\n",
    "            return target1, name1, target2, name2\n",
    "\n",
    "        group1, group2 = group\n",
    "        target1, name1, target2, name2 = get_pairs(group)\n",
    "        while target1 == target2:\n",
    "            target1, name1, target2, name2 = get_pairs(group)\n",
    "        assert target1 != target2\n",
    "        assert group1 != group2\n",
    "\n",
    "        f.write(f\"{target1:8s}\\t{name1}\\t{target2:8s}\\t{name2}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face = join_face_df(DTFR, \"aihub_family\")\n",
    "valid_uuids = read_split(\"test\")\n",
    "x_test = face.loc[valid_uuids]\n",
    "x_test = x_test.reset_index().reset_index().set_index(\"uuid\")\n",
    "df = x_test.groupby([\"age_group\"]).agg(list)[['index']]\n",
    "df = df[df.index != \"above\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BASIC-A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORY = \"BASIC-A\"\n",
    "dir_category = \"test\"\n",
    "\n",
    "target_pair = f\"pairs/{dir_category}/pairs_{CATEGORY}.txt\"\n",
    "os.makedirs(os.path.dirname(target_pair), exist_ok=True)\n",
    "print(target_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(22)\n",
    "unique_age_group = [_ for _ in \"abcdefgh\"]\n",
    "index_list = np.random.choice(len(unique_age_group), 6000, replace=True)\n",
    "selected_age_group = np.array(unique_age_group)[index_list]\n",
    "\n",
    "with open(target_pair, \"w\") as f:\n",
    "    f.write(f\"{NUM_FOLDS} {NUM_PAIRS}\\n\")\n",
    "    for age_group in tqdm(selected_age_group):\n",
    "        pid1, pid2 = random.sample(df.loc[age_group][\"index\"], 2)\n",
    "        row1, row2 = x_test.iloc[pid1], x_test.iloc[pid2]\n",
    "        out = row1.target, row1.name, row2.target, row2.name\n",
    "        target1, name1, target2, name2 = out\n",
    "        while target1 == target2:\n",
    "            pid1, pid2 = random.sample(df.loc[age_group][\"index\"], 2)\n",
    "            row1, row2 = x_test.iloc[pid1], x_test.iloc[pid2]\n",
    "            target1, name1, target2, name2 = row1.target, row1.name, row2.target, row2.name\n",
    "        age_group1, age_group2 = row1.age_group, row2.age_group\n",
    "        assert target1 != target2\n",
    "        assert age_group1 == age_group2\n",
    "        f.write(f\"{target1:8s}\\t{name1}\\t{target2:8s}\\t{name2}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BASIC-AC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORY = \"BASIC-AC\"\n",
    "dir_category = \"test\"\n",
    "\n",
    "target_pair = f\"pairs/{dir_category}/pairs_{CATEGORY}.txt\"\n",
    "os.makedirs(os.path.dirname(target_pair), exist_ok=True)\n",
    "print(target_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(22)\n",
    "unique_age_group = [_ for _ in \"abcdefgh\"]\n",
    "unique_age_group_total_pairs = list(combinations(unique_age_group, 2))\n",
    "index_list = np.random.choice(len(unique_age_group_total_pairs), 6000, replace=True)\n",
    "selected_age_group_pairs = np.array(unique_age_group_total_pairs)[index_list]\n",
    "\n",
    "with open(target_pair, \"w\") as f:\n",
    "    f.write(f\"{NUM_FOLDS} {NUM_PAIRS}\\n\")\n",
    "    for age_groups in tqdm(selected_age_group_pairs):\n",
    "\n",
    "        def get_target_and_name(age_group, df=x_test):\n",
    "            row = df[df.age_group == age_group].sample()\n",
    "            target, name = row.target.item(), row.iloc[0].name\n",
    "            return target, name\n",
    "\n",
    "        def get_pairs(age_group):\n",
    "            age_group1, age_group2 = age_group\n",
    "            target1, name1 = get_target_and_name(age_group1)\n",
    "            target2, name2 = get_target_and_name(age_group2)\n",
    "            return target1, name1, target2, name2\n",
    "\n",
    "        age_group1, age_group2 = age_groups\n",
    "        target1, name1, target2, name2 = get_pairs(age_groups)\n",
    "        while target1 == target2:\n",
    "            target1, name1, target2, name2 = get_pairs(age_groups)\n",
    "        assert target1 != target2\n",
    "        assert age_group1 != age_group2\n",
    "        \n",
    "        f.write(f\"{target1:8s}\\t{name1}\\t{target2:8s}\\t{name2}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face = join_face_df(DTFR, \"aihub_family\")\n",
    "valid_uuids = read_split(\"test\")\n",
    "x_test = face.loc[valid_uuids]\n",
    "x_test = x_test.reset_index().reset_index().set_index(\"uuid\")\n",
    "df = x_test.groupby([\"family_id\"]).agg(list)[['index']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BASIC-F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORY = \"BASIC-F\"\n",
    "dir_category = \"test\"\n",
    "\n",
    "target_pair = f\"pairs/{dir_category}/pairs_{CATEGORY}.txt\"\n",
    "os.makedirs(os.path.dirname(target_pair), exist_ok=True)\n",
    "print(target_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(22)\n",
    "unique_group = x_test.family_id.unique()\n",
    "index_list = np.random.choice(len(unique_group), 6000, replace=True)\n",
    "selected_group = np.array(unique_group)[index_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(target_pair, \"w\") as f:\n",
    "    f.write(f\"{NUM_FOLDS} {NUM_PAIRS}\\n\")\n",
    "    for group in tqdm(selected_group):\n",
    "        pid1, pid2 = random.sample(df.loc[group][\"index\"], 2)\n",
    "        row1, row2 = x_test.iloc[pid1], x_test.iloc[pid2]\n",
    "        out = row1.target, row1.name, row2.target, row2.name\n",
    "        target1, name1, target2, name2 = out\n",
    "        while target1 == target2:\n",
    "            pid1, pid2 = random.sample(df.loc[group][\"index\"], 2)\n",
    "            row1, row2 = x_test.iloc[pid1], x_test.iloc[pid2]\n",
    "            target1, name1, target2, name2 = (\n",
    "                row1.target,\n",
    "                row1.name,\n",
    "                row2.target,\n",
    "                row2.name,\n",
    "            )\n",
    "        group1, group2 = row1.family_id, row2.family_id\n",
    "        assert target1 != target2\n",
    "        assert group1 == group2\n",
    "        f.write(f\"{target1:8s}\\t{name1}\\t{target2:8s}\\t{name2}\\n\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BASIC-FC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORY = \"BASIC-FC\"\n",
    "dir_category = \"test\"\n",
    "\n",
    "target_pair = f\"pairs/{dir_category}/pairs_{CATEGORY}.txt\"\n",
    "os.makedirs(os.path.dirname(target_pair), exist_ok=True)\n",
    "print(target_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(22)\n",
    "unique_group_total_pairs = list(combinations(unique_group, 2))\n",
    "index_list = np.random.choice(len(unique_group_total_pairs), 6000, replace=True)\n",
    "selected_group_pairs = np.array(unique_group_total_pairs)[index_list]\n",
    "\n",
    "with open(target_pair, \"w\") as f:\n",
    "    f.write(f\"{NUM_FOLDS} {NUM_PAIRS}\\n\")\n",
    "    for group in tqdm(selected_group_pairs):\n",
    "\n",
    "        def get_target_and_name(group, df=x_test):\n",
    "            row = df[df.family_id == group].sample()\n",
    "            target, name = row.target.item(), row.iloc[0].name\n",
    "            return target, name\n",
    "\n",
    "        def get_pairs(group):\n",
    "            group1, group2 = group\n",
    "            target1, name1 = get_target_and_name(group1)\n",
    "            target2, name2 = get_target_and_name(group2)\n",
    "            return target1, name1, target2, name2\n",
    "\n",
    "        group1, group2 = group\n",
    "        target1, name1, target2, name2 = get_pairs(group)\n",
    "        while target1 == target2:\n",
    "            target1, name1, target2, name2 = get_pairs(group)\n",
    "        assert target1 != target2\n",
    "        assert group1 != group2\n",
    "\n",
    "        f.write(f\"{target1:8s}\\t{name1}\\t{target2:8s}\\t{name2}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Under Family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fpt.data import join_face_df\n",
    "from fpt.split import read_split\n",
    "from fpt.path import DTFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FOLDS = 10\n",
    "NUM_PAIRS = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face = join_face_df(DTFR, \"aihub_family\")\n",
    "valid_uuids = read_split(\"test\")\n",
    "x_test = face.loc[valid_uuids]\n",
    "x_test = x_test[x_test.age_group != \"above\"]\n",
    "x_test = x_test.reset_index().reset_index().set_index(\"uuid\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = x_test.groupby([\"age_group\", \"family_id\", \"personal_id\"]).agg(list)[['index']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = []\n",
    "for index, group in df.groupby(['age_group', 'family_id']):\n",
    "    if len(group) < 2:\n",
    "        continue\n",
    "    for candidate in itertools.combinations(group.loc[index].index, 2):\n",
    "        pid1, pid2 = candidate\n",
    "        index_list1 = group.loc[(*index, pid1)].item()\n",
    "        index_list2 = group.loc[(*index, pid2)].item()\n",
    "        pairs = itertools.product(index_list1, index_list2)\n",
    "        for pair in pairs:\n",
    "            candidates.append(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_pairs = random.sample(candidates, 6000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FAMILY-A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORY = \"FAMILY-A\"\n",
    "dir_category = \"test\"\n",
    "\n",
    "target_pair = f\"pairs/{dir_category}/pairs_{CATEGORY}.txt\"\n",
    "os.makedirs(os.path.dirname(target_pair), exist_ok=True)\n",
    "print(target_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(target_pair, \"w\") as f:\n",
    "    f.write(f\"{NUM_FOLDS} {NUM_PAIRS}\\n\")\n",
    "    for group in tqdm(selected_pairs):\n",
    "        pid1, pid2 = group\n",
    "        row1, row2 = x_test.iloc[pid1], x_test.iloc[pid2]\n",
    "        out = row1.target, row1.name, row2.target, row2.name\n",
    "        target1, name1, target2, name2 = out\n",
    "        assert target1 != target2\n",
    "        assert row1.age_group == row2.age_group\n",
    "        assert row1.family_id == row2.family_id\n",
    "        f.write(f\"{target1:8s}\\t{name1}\\t{target2:8s}\\t{name2}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FAMILY-CA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORY = \"FAMILY-CA\"\n",
    "dir_category = \"test\"\n",
    "\n",
    "target_pair = f\"pairs/{dir_category}/pairs_{CATEGORY}.txt\"\n",
    "os.makedirs(os.path.dirname(target_pair), exist_ok=True)\n",
    "print(target_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = x_test.groupby([\"age_group\", \"family_id\"]).agg(list)[['index']]\n",
    "candidates = []\n",
    "\n",
    "np.random.seed(22)\n",
    "random.seed(22)\n",
    "\n",
    "for index, group in df.groupby(\"age_group\"):\n",
    "    all_afid = list(group.index)\n",
    "    for candidate in itertools.combinations(all_afid, 2):\n",
    "        candidates.append(candidate)\n",
    "selected_candidates = random.sample(candidates, 6000)\n",
    "with open(target_pair, \"w\") as f:\n",
    "    f.write(f\"{NUM_FOLDS} {NUM_PAIRS}\\n\")\n",
    "    for dfidx1, dfidx2 in tqdm(selected_candidates):\n",
    "        idx1 = random.sample(df.loc[dfidx1].item(), 1)\n",
    "        idx2 = random.sample(df.loc[dfidx2].item(), 1)\n",
    "        row1 = x_test.iloc[idx1]\n",
    "        row2 = x_test.iloc[idx2]\n",
    "        target1, name1 = row1.target.item(), row1.index.item()\n",
    "        target2, name2 = row2.target.item(), row2.index.item()\n",
    "        assert target1 != target2\n",
    "        assert row1.age_group.item() == row2.age_group.item()\n",
    "        assert row1.family_id.item() != row2.family_id.item()\n",
    "        f.write(f\"{target1:8s}\\t{name1}\\t{target2:8s}\\t{name2}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = x_test.groupby([\"gender\", \"family_id\", \"personal_id\"]).agg(list)[['index']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = []\n",
    "for index, group in df.groupby(['gender', 'family_id']):\n",
    "    if len(group) < 2:\n",
    "        continue\n",
    "    for candidate in itertools.combinations(group.loc[index].index, 2):\n",
    "        pid1, pid2 = candidate\n",
    "        index_list1 = group.loc[(*index, pid1)].item()\n",
    "        index_list2 = group.loc[(*index, pid2)].item()\n",
    "        pairs = itertools.product(index_list1, index_list2)\n",
    "        for pair in pairs:\n",
    "            candidates.append(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_pairs = random.sample(candidates, 6000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FAMILY-G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORY = \"FAMILY-G\"\n",
    "dir_category = \"test\"\n",
    "\n",
    "target_pair = f\"pairs/{dir_category}/pairs_{CATEGORY}.txt\"\n",
    "os.makedirs(os.path.dirname(target_pair), exist_ok=True)\n",
    "print(target_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(target_pair, \"w\") as f:\n",
    "    f.write(f\"{NUM_FOLDS} {NUM_PAIRS}\\n\")\n",
    "    for group in tqdm(selected_pairs):\n",
    "        pid1, pid2 = group\n",
    "        row1, row2 = x_test.iloc[pid1], x_test.iloc[pid2]\n",
    "        out = row1.target, row1.name, row2.target, row2.name\n",
    "        target1, name1, target2, name2 = out\n",
    "        assert target1 != target2\n",
    "        assert row1.gender == row2.gender\n",
    "        assert row1.family_id == row2.family_id\n",
    "        f.write(f\"{target1:8s}\\t{name1}\\t{target2:8s}\\t{name2}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FAMILY-CG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORY = \"FAMILY-CG\"\n",
    "dir_category = \"test\"\n",
    "\n",
    "target_pair = f\"pairs/{dir_category}/pairs_{CATEGORY}.txt\"\n",
    "os.makedirs(os.path.dirname(target_pair), exist_ok=True)\n",
    "print(target_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = x_test.groupby([\"gender\", \"family_id\"]).agg(list)[['index']]\n",
    "candidates = []\n",
    "\n",
    "np.random.seed(22)\n",
    "random.seed(22)\n",
    "\n",
    "for index, group in df.groupby(\"gender\"):\n",
    "    all_gfid = list(group.index)\n",
    "    for candidate in itertools.combinations(all_gfid, 2):\n",
    "        candidates.append(candidate)\n",
    "selected_candidates = random.sample(candidates, 6000)\n",
    "with open(target_pair, \"w\") as f:\n",
    "    f.write(f\"{NUM_FOLDS} {NUM_PAIRS}\\n\")\n",
    "    for dfidx1, dfidx2 in tqdm(selected_candidates):\n",
    "        idx1 = random.sample(df.loc[dfidx1].item(), 1)\n",
    "        idx2 = random.sample(df.loc[dfidx2].item(), 1)\n",
    "        row1 = x_test.iloc[idx1]\n",
    "        row2 = x_test.iloc[idx2]\n",
    "        target1, name1 = row1.target.item(), row1.index.item()\n",
    "        target2, name2 = row2.target.item(), row2.index.item()\n",
    "        assert target1 != target2\n",
    "        assert row1.gender.item() == row2.gender.item()\n",
    "        assert row1.family_id.item() != row2.family_id.item()\n",
    "        f.write(f\"{target1:8s}\\t{name1}\\t{target2:8s}\\t{name2}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age/Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = x_test.groupby([\"gender\", \"age_group\", \"family_id\", \"personal_id\"]).agg(list)[['index']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = []\n",
    "for index, group in df.groupby(['gender', \"age_group\", 'family_id']):\n",
    "    if len(group) < 2:\n",
    "        continue\n",
    "    for candidate in itertools.combinations(group.loc[index].index, 2):\n",
    "        pid1, pid2 = candidate\n",
    "        index_list1 = group.loc[(*index, pid1)].item()\n",
    "        index_list2 = group.loc[(*index, pid2)].item()\n",
    "        pairs = itertools.product(index_list1, index_list2)\n",
    "        for pair in pairs:\n",
    "            candidates.append(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_pairs = random.sample(candidates, 6000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FAMILY-AG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORY = \"FAMILY-AG\"\n",
    "dir_category = \"test\"\n",
    "\n",
    "target_pair = f\"pairs/{dir_category}/pairs_{CATEGORY}.txt\"\n",
    "os.makedirs(os.path.dirname(target_pair), exist_ok=True)\n",
    "print(target_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(target_pair, \"w\") as f:\n",
    "    f.write(f\"{NUM_FOLDS} {NUM_PAIRS}\\n\")\n",
    "    for group in tqdm(selected_pairs):\n",
    "        pid1, pid2 = group\n",
    "        row1, row2 = x_test.iloc[pid1], x_test.iloc[pid2]\n",
    "        out = row1.target, row1.name, row2.target, row2.name\n",
    "        target1, name1, target2, name2 = out\n",
    "        assert target1 != target2\n",
    "        assert row1.gender == row2.gender\n",
    "        assert row1.age_group == row2.age_group\n",
    "        assert row1.family_id == row2.family_id\n",
    "        f.write(f\"{target1:8s}\\t{name1}\\t{target2:8s}\\t{name2}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FAMILY-CAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORY = \"FAMILY-CAG\"\n",
    "dir_category = \"test\"\n",
    "\n",
    "target_pair = f\"pairs/{dir_category}/pairs_{CATEGORY}.txt\"\n",
    "os.makedirs(os.path.dirname(target_pair), exist_ok=True)\n",
    "print(target_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = x_test.groupby([\"gender\", \"age_group\", \"family_id\"]).agg(list)[[\"index\"]]\n",
    "candidates = []\n",
    "\n",
    "np.random.seed(22)\n",
    "random.seed(22)\n",
    "\n",
    "for index, group in df.groupby([\"gender\", \"age_group\"]):\n",
    "    all_gfid = list(group.index)\n",
    "    for candidate in itertools.combinations(all_gfid, 2):\n",
    "        candidates.append(candidate)\n",
    "selected_candidates = random.sample(candidates, 6000)\n",
    "with open(target_pair, \"w\") as f:\n",
    "    f.write(f\"{NUM_FOLDS} {NUM_PAIRS}\\n\")\n",
    "    for dfidx1, dfidx2 in tqdm(selected_candidates):\n",
    "        idx1 = random.sample(df.loc[dfidx1].item(), 1)\n",
    "        idx2 = random.sample(df.loc[dfidx2].item(), 1)\n",
    "        row1 = x_test.iloc[idx1]\n",
    "        row2 = x_test.iloc[idx2]\n",
    "        target1, name1 = row1.target.item(), row1.index.item()\n",
    "        target2, name2 = row2.target.item(), row2.index.item()\n",
    "        assert target1 != target2\n",
    "        assert row1.gender.item() == row2.gender.item()\n",
    "        assert row1.age_group.item() == row2.age_group.item()\n",
    "        assert row1.family_id.item() != row2.family_id.item()\n",
    "        f.write(f\"{target1:8s}\\t{name1}\\t{target2:8s}\\t{name2}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd \"/home/jupyter/family-photo-tree\"\n",
    "%pwd\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.modules.distance import PairwiseDistance\n",
    "from fpt.path import DATA\n",
    "from fpt.model import Model\n",
    "from fpt.config import cfg\n",
    "from fpt.dataset import AIHubDataset\n",
    "from fpt.logger import initialize_wandb\n",
    "from fpt.utils import log_verification_output\n",
    "from fpt.transform import aihub_valid_transforms\n",
    "from facenet.validate_aihub import validate_aihub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logger\n",
    "wandb_logger = initialize_wandb(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_task = \"CASE1C\"\n",
    "checkpoint = \"230529_0140\"\n",
    "best_distance = 28.465\n",
    "cfg.project_name = \"log_test_validation\"\n",
    "\n",
    "# dataloader\n",
    "aihub_pairs_case1c_dataset = AIHubDataset(\n",
    "    dir=DATA / \"face-image/test_aihub_family\",\n",
    "    pairs_path=DATA / f\"pairs/test/pairs_{validate_task.upper()}.txt\",\n",
    "    transform=aihub_valid_transforms,\n",
    ")\n",
    "test_loader = DataLoader(aihub_pairs_case1c_dataset, batch_size=32)\n",
    "\n",
    "# model\n",
    "model = Model(cfg)\n",
    "model_path = f\"/home/jongphago/family-photo-tree/work_dirs/aihub_r50_onegpu/{checkpoint}_ArcFace/model.pt\"\n",
    "model.load_embedding(path=model_path)\n",
    "\n",
    "# distance_metric\n",
    "l2_distance = PairwiseDistance(p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = 0\n",
    "for a, b, label in tqdm(test_loader):\n",
    "    output_a = model.embedding(a.cuda())\n",
    "    output_b = model.embedding(b.cuda())\n",
    "    distance = l2_distance.forward(output_a, output_b)  # Euclidean distance\n",
    "    result = torch.eq(distance.cpu().detach() < best_distance, label)\n",
    "    out += result.sum().detach()\n",
    "\n",
    "print(f\"{out / len(test_loader.dataset):4.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_output = validate_aihub(\n",
    "    model.embedding, test_loader, \"r50\", 1, task=validate_task\n",
    ")\n",
    "log_verification_output(validate_output, wandb_logger, validate_task.capitalize(), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dataframe_image as dfi\n",
    "from easydict import EasyDict as edict\n",
    "from fpt.data import join_face_df\n",
    "from fpt.split import read_split\n",
    "from fpt.path import DTFR, DATA\n",
    "\n",
    "pd.set_option(\"display.float_format\", \"{:.4f}\".format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.font_manager as fm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import rc\n",
    "\n",
    "font_path = \"/usr/share/fonts/NanumFont/NanumGothicBold.ttf\"\n",
    "fontprop = fm.FontProperties(fname=font_path, size=18)\n",
    "\n",
    "# 한글 폰트 설정\n",
    "font_name = fm.FontProperties(\n",
    "    fname=\"/usr/share/fonts/NanumFont/NanumGothicBold.ttf\"\n",
    ").get_name()\n",
    "rc(\"font\", family=font_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set global figure background color\n",
    "plt.rcParams[\"figure.facecolor\"] = \"white\"\n",
    "\n",
    "sns.set(style=\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path(\"/home/jongphago/family-photo-tree\")\n",
    "\n",
    "\n",
    "def savefig(target: str, extension=\".png\"):\n",
    "    if not target.endswith(extension):\n",
    "        target += extension\n",
    "    image_path = ROOT / target\n",
    "    dirname = os.path.dirname(image_path)\n",
    "    if not os.path.exists(dirname):\n",
    "        os.makedirs(dirname)\n",
    "    plt.savefig(image_path, facecolor=\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_extension(path):\n",
    "    if os.path.exists(path + \".jpg\"):\n",
    "        return path + \".jpg\"\n",
    "    elif os.path.exists(path + \".png\"):\n",
    "        return path + \".png\"\n",
    "    else:\n",
    "        raise RuntimeError('No file \"%s\" with extension png or jpg.' % path)\n",
    "\n",
    "\n",
    "def get_distance_list(distance_path):\n",
    "    with open(distance_path, \"r\") as f:\n",
    "        l = f.readline().rstrip()\n",
    "        best_distance = float(l.split(\", \")[1])\n",
    "        lines = f.readlines()\n",
    "        distances = [float(l.rstrip()) for l in lines]\n",
    "        assert len(distances) == 6000\n",
    "    return distances, best_distance\n",
    "\n",
    "\n",
    "def get_lr(df, prop_name, is_sort=False):\n",
    "    new = df[[f\"{prop_name}_left\", f\"{prop_name}_right\", \"distance\", \"correct\"]].copy()\n",
    "    \n",
    "    if is_sort:\n",
    "        sorted_lr = pd.DataFrame(\n",
    "            np.sort(new[[f\"{prop_name}_left\", f\"{prop_name}_right\"]]),\n",
    "            columns=[f\"{prop_name}_left\", f\"{prop_name}_right\"],\n",
    "        )\n",
    "        new.update(sorted_lr)\n",
    "\n",
    "    # apply sorted function on total_list\n",
    "    new[\"total_list\"] = df[[f\"{prop_name}_left\", f\"{prop_name}_right\"]].apply(\n",
    "        lambda x: sorted(x), axis=1\n",
    "    )\n",
    "\n",
    "    new[\"total\"] = new[\"total_list\"].apply(lambda x: \", \".join(map(str, x)))\n",
    "\n",
    "    # set property\n",
    "    best_distance = df.best_distance\n",
    "    pair_name = df.pair_name\n",
    "    checkpoint = df.checkpoint\n",
    "    model_type = df.model_type\n",
    "    setattr(new, \"pair_name\", pair_name)\n",
    "    setattr(new, \"checkpoint\", checkpoint)\n",
    "    setattr(new, \"model_type\", model_type)\n",
    "    setattr(new, \"best_distance\", best_distance)\n",
    "    return new\n",
    "\n",
    "\n",
    "def makedirs(table_name):\n",
    "    root = \"/home/jupyter/family-photo-tree/utils/dataset\"\n",
    "    dir_name = os.path.dirname(table_name)\n",
    "    export_dir = os.path.join(root, dir_name)\n",
    "    os.makedirs(export_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# face dataframe\n",
    "face = join_face_df(DTFR, \"aihub_family\")\n",
    "face[\"personal_id\"] = face[\"personal_id\"].str.replace(\"\\d+\", \"\", regex=True)\n",
    "valid_uuids = read_split(\"test\")\n",
    "\n",
    "x_test = face.loc[valid_uuids]\n",
    "x_test = x_test[x_test.age_group != \"above\"]\n",
    "x_test = x_test.reset_index().reset_index().set_index(\"uuid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(pair_name, model_type, checkpoint, x_test=x_test):\n",
    "    def get_path(pair_name, model_type, checkpoint):\n",
    "        distance_path = DATA / f\"distance/{model_type}/{checkpoint}/{pair_name}.txt\"\n",
    "        pairs_path = f\"pairs/test/pairs_{pair_name}.txt\"\n",
    "        return distance_path, pairs_path\n",
    "\n",
    "    # get path\n",
    "    distance_path, pairs_path = get_path(pair_name, model_type, checkpoint)\n",
    "\n",
    "    # Distance array\n",
    "    distances, best_distance = get_distance_list(distance_path)\n",
    "    distances = np.array([distances, np.array(distances) > best_distance], dtype=int).T\n",
    "\n",
    "    # pairs data path\n",
    "    os.makedirs(os.path.dirname(pairs_path), exist_ok=True)\n",
    "    aihub_dir = DATA / \"face-image/test_aihub_family\"\n",
    "\n",
    "    # pairs df (6000, 6)\n",
    "    pairs = []\n",
    "    is_sames = []\n",
    "    with open(pairs_path, \"r\") as f:\n",
    "        for line in f.readlines()[1:]:\n",
    "            pair = line.strip().split()\n",
    "            pairs.append(pair)\n",
    "            is_sames.append(True if len(pair) == 3 else False)\n",
    "\n",
    "    pairs = np.array(pairs, dtype=object)\n",
    "    is_sames = np.array(is_sames, dtype=np.int64)[:, np.newaxis]\n",
    "    columns = [\"issame\", \"ltarget\", \"luuid\", \"rtarget\", \"ruuid\", \"distance\", \"correct\"]\n",
    "    pairs_df = pd.DataFrame(\n",
    "        np.hstack((is_sames, pairs, distances)),\n",
    "        columns=columns,\n",
    "    )  # (6000, 6)\n",
    "\n",
    "    # path_df\n",
    "    nrof_skipped_pairs = 0\n",
    "    path_list = []\n",
    "    issame_list = []\n",
    "    for pair in pairs:\n",
    "        if len(pair) == 3:\n",
    "            path0 = add_extension(os.path.join(aihub_dir, pair[0], pair[1]))\n",
    "            path1 = add_extension(os.path.join(aihub_dir, pair[0], pair[2]))\n",
    "            issame = True\n",
    "        elif len(pair) == 4:\n",
    "            path0 = add_extension(os.path.join(aihub_dir, pair[0], pair[1]))\n",
    "            path1 = add_extension(os.path.join(aihub_dir, pair[2], pair[3]))\n",
    "            issame = False\n",
    "        if os.path.exists(path0) and os.path.exists(\n",
    "            path1\n",
    "        ):  # Only add the pair if both paths exist\n",
    "            path_list.append((path0, path1, issame))\n",
    "            issame_list.append(issame)\n",
    "        else:\n",
    "            nrof_skipped_pairs += 1\n",
    "\n",
    "    if nrof_skipped_pairs > 0:\n",
    "        print(\"Skipped %d image pairs\" % nrof_skipped_pairs)\n",
    "\n",
    "    path_df = pd.DataFrame(\n",
    "        path_list,\n",
    "        columns=(\"image_left\", \"image_right\", \"issame\"),\n",
    "    )  # (6000, 3)\n",
    "\n",
    "    # df\n",
    "    temp_x_test = x_test.reset_index().set_index(\"index\")  # (8147, 15)\n",
    "    temp_merged = pd.merge(\n",
    "        pairs_df,\n",
    "        temp_x_test,\n",
    "        left_on=\"luuid\",\n",
    "        right_on=\"uuid\",\n",
    "    )\n",
    "    df = pd.merge(\n",
    "        temp_merged,\n",
    "        temp_x_test,\n",
    "        left_on=\"ruuid\",\n",
    "        right_on=\"uuid\",\n",
    "        suffixes=[\"_left\", \"_right\"],\n",
    "    )\n",
    "    df.correct = df.correct.astype(int)\n",
    "\n",
    "    # set property\n",
    "    setattr(df, \"pair_name\", pair_name)\n",
    "    setattr(df, \"checkpoint\", checkpoint)\n",
    "    setattr(df, \"model_type\", model_type)\n",
    "    setattr(df, \"best_distance\", best_distance)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grouped_ratio(lr, prop_name):\n",
    "    grouped = lr.groupby(\"total\").count().total_list.to_frame() / len(lr)\n",
    "    grouped.columns = [f\"{prop_name}_pair_ratio\"]\n",
    "    setattr(grouped, \"prop_name\", prop_name)\n",
    "    return grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# capture dataframe\n",
    "def capture_df(grouped, pair_name, prop_name):\n",
    "    grouped_shape = '{}x{}'.format(*grouped.shape)\n",
    "    image_path = f\"export/{pair_name}/{prop_name}/lr-{prop_name}_pair_ratio-{grouped_shape}.png\"\n",
    "    makedirs(image_path)\n",
    "    dfi.export(grouped, image_path, table_conversion=\"matplotlib\")\n",
    "    print(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"single-fr-ver-1\"\n",
    "checkpoint = \"230529_0140\"\n",
    "pair_names = [\n",
    "    \"BASIC-G\", \"BASIC-GC\",\n",
    "    \"BASIC-A\", \"BASIC-AC\",\n",
    "    \"BASIC-F\", \"BASIC-FC\",\n",
    "    \"FAMILY-A\", \"FAMILY-CA\",\n",
    "    \"FAMILY-G\", \"FAMILY-CG\",\n",
    "    \"FAMILY-AG\", \"FAMILY-CAG\",\n",
    "    # \"BASIC-FN\",\n",
    "    # \"PERSONAL-A\", \"PERSONAL-AC\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = edict(\n",
    "    {\n",
    "        pair_name.replace(\"-\", \"\").lower(): get_df(pair_name, model_type, checkpoint)\n",
    "        for pair_name in pair_names\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_name_dict = edict({\n",
    "    'gender':'성별',\n",
    "    'age_group': '나이 그룹',\n",
    "    'age': '나이',\n",
    "    'category': '이미지 카테고리'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pair_list = [df_dict.basicg, df_dict.basicgc]\n",
    "pair_list = [df_dict.basica, df_dict.basicac]\n",
    "# pair_list = [df_dict.basicf, df_dict.basicfc]\n",
    "# pair_list = [df_dict.familya, df_dict.familyca]\n",
    "# pair_list = [df_dict.familyg, df_dict.familycg]\n",
    "# pair_list = [df_dict.familyag, df_dict.familycag]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratio table"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_data_ratio_table(prop_name, pair_list):\n",
    "    kor_prop_name = prop_name_dict[prop_name]\n",
    "    result = []\n",
    "    a = x_test.groupby(prop_name).count().label / len(x_test)\n",
    "    setattr(a, \"name\", \"x_test\")\n",
    "    result.append(a)\n",
    "    pair_name_list = []\n",
    "    for sub_task in pair_list:\n",
    "        lr = get_lr(sub_task, prop_name)\n",
    "        for d in [\"left\", \"right\"]:\n",
    "            b = lr.groupby(f\"{prop_name}_{d}\").count().total / len(lr)\n",
    "            setattr(b, \"name\", f\"{sub_task.pair_name}-{d}\")\n",
    "            result.append(b)\n",
    "        pair_name_list.append(sub_task.pair_name)\n",
    "    print(f'Table | {\"와 \".join(pair_name_list)}의 {kor_prop_name} 데이터 구성 비율')\n",
    "    return pd.DataFrame(result, index=[r.name for r in result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_name = 'gender'\n",
    "draw_data_ratio_table(prop_name, pair_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### age_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_name = 'age_group'\n",
    "draw_data_ratio_table(prop_name, pair_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_name = 'category'\n",
    "draw_data_ratio_table(prop_name, pair_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import font_manager\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_pair_ratio_heatmap(prop_name, pair_list):\n",
    "    kor_prop_name = prop_name_dict[prop_name]\n",
    "\n",
    "    # 한글 폰트 설정\n",
    "    font_name = font_manager.FontProperties(\n",
    "        fname=\"/usr/share/fonts/NanumFont/NanumGothicBold.ttf\"\n",
    "    ).get_name()\n",
    "    plt.rc(\"font\", family=font_name)\n",
    "\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(20, 8))\n",
    "\n",
    "    # Compute the global min and max to use for all heatmaps\n",
    "    vmin = float(\"inf\")\n",
    "    vmax = float(\"-inf\")\n",
    "\n",
    "    for sub_task in pair_list:\n",
    "        lr = get_lr(sub_task, prop_name, is_sort=True)\n",
    "        heatmap_data = lr.groupby(\n",
    "            [f\"{prop_name}_left\", f\"{prop_name}_right\"]\n",
    "        ).count().correct / len(lr)\n",
    "        vmin = min(vmin, heatmap_data.min())\n",
    "        vmax = max(vmax, heatmap_data.max())\n",
    "\n",
    "    pair_name_list = []\n",
    "    copied = None\n",
    "    for i, sub_task in enumerate(pair_list):\n",
    "        lr = get_lr(sub_task, prop_name, is_sort=True)\n",
    "\n",
    "        # DataFrame을 pivot 형태로 변환\n",
    "        heatmap_data = lr.groupby(\n",
    "            [f\"{prop_name}_left\", f\"{prop_name}_right\"]\n",
    "        ).count().correct / len(lr)\n",
    "        heatmap_data = heatmap_data.reset_index()\n",
    "        heatmap_data = heatmap_data.pivot(\n",
    "            f\"{prop_name}_left\", f\"{prop_name}_right\", \"correct\"\n",
    "        )\n",
    "        if copied is None:\n",
    "            copied = heatmap_data.copy()\n",
    "\n",
    "        # heatmap 그리기\n",
    "        sns.heatmap(\n",
    "            heatmap_data,\n",
    "            cmap=\"YlGnBu\",\n",
    "            annot=True,\n",
    "            fmt=\".2f\",\n",
    "            ax=axs[i],\n",
    "            vmin=vmin,\n",
    "            vmax=vmax,\n",
    "        )\n",
    "\n",
    "        # x, y 축 라벨 및 타이틀 설정\n",
    "        axs[i].set_title(f\"[{lr.pair_name}] {kor_prop_name} 쌍 비율\", fontsize=14)\n",
    "        axs[i].set_xlabel(f\"오른쪽 {kor_prop_name}\", fontsize=12)\n",
    "        axs[i].set_ylabel(f\"왼쪽 {kor_prop_name}\", fontsize=12)\n",
    "\n",
    "        m = heatmap_data.stack().mean()\n",
    "        d = heatmap_data.stack().std()\n",
    "        print(f\"평균 {m:.4f}, 표준편차 {d:.4f}\")\n",
    "        pair_name_list.append(sub_task.pair_name)\n",
    "    print(f'Figure | {\"와 \".join(pair_name_list)}의 {kor_prop_name} 데이터 쌍 비율')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return copied - heatmap_data\n",
    "\n",
    "def draw_instance_ratio_heatmap(prop_name, pair_list):\n",
    "    kor_prop_name = prop_name_dict[prop_name]\n",
    "\n",
    "    # 한글 폰트 설정\n",
    "    font_name = font_manager.FontProperties(\n",
    "        fname=\"/usr/share/fonts/NanumFont/NanumGothicBold.ttf\"\n",
    "    ).get_name()\n",
    "    plt.rc(\"font\", family=font_name)\n",
    "\n",
    "    result = []\n",
    "    a = x_test.groupby(prop_name).count().label / len(x_test)\n",
    "    setattr(a, \"name\", \"x_test\")\n",
    "    result.append(a)\n",
    "\n",
    "    pair_name_list = []\n",
    "    for sub_task in pair_list:\n",
    "        lr = get_lr(sub_task, prop_name)\n",
    "        for d in [\"left\", \"right\"]:\n",
    "            b = lr.groupby(f\"{prop_name}_{d}\").count().total / len(lr)\n",
    "            setattr(b, \"name\", f\"{sub_task.pair_name}-{d}\")\n",
    "            result.append(b)\n",
    "            m, d = b.mean(), b.std()\n",
    "            print(f\"평균 {m:.4f}, 표준편차 {d:.4f}\")\n",
    "        pair_name_list.append(sub_task.pair_name)\n",
    "    print(f'Figure | {\"와 \".join(pair_name_list)}의 {kor_prop_name} 비율 히트맵')\n",
    "\n",
    "    out = pd.DataFrame(result, index=[r.name for r in result])  # (5, 8)\n",
    "\n",
    "    # seaborn heatmap 사용\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.heatmap(\n",
    "        out,\n",
    "        annot=True,\n",
    "        cmap=\"YlGnBu\",\n",
    "        fmt=\".3g\",\n",
    "        linewidths=0.5,\n",
    "        cbar_kws={\"shrink\": 0.5},\n",
    "    )\n",
    "\n",
    "    # Setting labels and title\n",
    "    title = f\"[{','.join(pair_name_list)}] {kor_prop_name} 비율 히트맵\"\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.xlabel(f\"{kor_prop_name}\", fontsize=14)\n",
    "    plt.ylabel(\"데이터셋\", fontsize=14)\n",
    "    plt.tick_params(axis=\"y\", rotation=0)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_name = \"gender\"\n",
    "draw_instance_ratio_heatmap(prop_name, pair_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_name = \"gender\"\n",
    "draw_pair_ratio_heatmap(prop_name, pair_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### age_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_name = \"age_group\"\n",
    "draw_instance_ratio_heatmap(prop_name, pair_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_name = \"age_group\"\n",
    "draw_pair_ratio_heatmap(prop_name, pair_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cateogry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_name = \"category\"\n",
    "draw_instance_ratio_heatmap(prop_name, pair_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_name = \"category\"\n",
    "draw_pair_ratio_heatmap(prop_name, pair_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KDE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_age_diff_kde(pair_list):\n",
    "    # 한글 폰트 설정\n",
    "    font_name = font_manager.FontProperties(fname=\"/usr/share/fonts/NanumFont/NanumGothicBold.ttf\").get_name()\n",
    "    plt.rc(\"font\", family=font_name)\n",
    "\n",
    "    sns.set(style=\"whitegrid\")  # setting seaborn style\n",
    "    plt.figure(figsize=(20, 6))  # specifying figure size\n",
    "\n",
    "    # Plotting KDE\n",
    "    plt.subplot(1, 2, 1)  # subplot to plot two graphs side by side\n",
    "\n",
    "    pair_name_list = []\n",
    "    for sub_task in pair_list:\n",
    "        sub_frame = abs(sub_task.age_left - sub_task.age_right)\n",
    "        pair_name_list.append(sub_task.pair_name)\n",
    "        sns.kdeplot(sub_frame, label=sub_task.pair_name, fill=True, alpha=0.1, cut=0)\n",
    "\n",
    "    plt.xlabel(\"나이 그룹 평균 나이 차이(절대값)\", fontsize=14, fontproperties=fontprop)\n",
    "    plt.ylabel(\"밀도\", fontsize=14, fontproperties=fontprop)\n",
    "    plt.xlim(0)\n",
    "    plt.title(f\"[{','.join(pair_name_list)}] 나이 그룹 평균 나이 차이에 대한 커널 밀도 추정\", fontsize=16, fontproperties=fontprop)\n",
    "    plt.legend(title=\"pair_name\", title_fontsize=\"13\", fontsize=12)\n",
    "\n",
    "    # Plotting Cumulative KDE\n",
    "    plt.subplot(1, 2, 2)  # subplot to plot two graphs side by side\n",
    "\n",
    "    for sub_task in pair_list:\n",
    "        sub_frame = abs(sub_task.age_left - sub_task.age_right)\n",
    "        sns.kdeplot(sub_frame, cumulative=True, label=sub_task.pair_name, fill=True, alpha=0.1, cut=3)\n",
    "\n",
    "    plt.xlabel(\"나이 또는 나이 그룹의 평균 나이 차이(절대값)\", fontsize=14, fontproperties=fontprop)\n",
    "    plt.ylabel(\"누적 밀도\", fontsize=14, fontproperties=fontprop)\n",
    "    plt.xlim(0)\n",
    "    plt.title(f\"[{','.join(pair_name_list)}] 나이 또는 나이 그룹 평균 나이 차이에 대한 누적 커널 밀도 추정\", fontsize=16, fontproperties=fontprop)\n",
    "    plt.legend(title=\"pair_name\", title_fontsize=\"13\", fontsize=12)\n",
    "\n",
    "    print(f\"Figure | {'와 '.join(pair_name_list)}의 나이 또는 나이 그룹 평균 나이 차이에 대한 누적 커널 밀도 추정\")\n",
    "    # Removing top and right borders\n",
    "    sns.despine()\n",
    "\n",
    "    plt.tight_layout()  # for better layout\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_age_diff_kde(pair_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_accuracy_table(prop_name, pair_list):\n",
    "    kor_prop_name = prop_name_dict[prop_name]\n",
    "    pair_name_list = []\n",
    "    dfs = []  # out DataFrame들을 담을 리스트를 생성합니다.\n",
    "    for sub_task in pair_list:\n",
    "        lr = get_lr(sub_task, prop_name)\n",
    "        out = lr.groupby('total')[['correct', 'distance']].mean()\n",
    "        out['pair_name'] = sub_task.pair_name\n",
    "        dfs.append(out)  # 리스트에 DataFrame을 추가합니다.\n",
    "        pair_name_list.append(sub_task.pair_name)\n",
    "    print(f'Table | {\"와 \".join(pair_name_list)}의 {kor_prop_name} 정확도')\n",
    "    \n",
    "    # 리스트의 모든 DataFrame들을 합칩니다.\n",
    "    final_df = pd.concat(dfs)  \n",
    "\n",
    "    # 통계 행을 생성합니다.\n",
    "    temp_total = final_df.groupby(\"pair_name\").mean()\n",
    "    temp_total[\"total\"] = \"total\"\n",
    "\n",
    "    print(f\"정확도의 차이: {abs(np.subtract(*[i for i in temp_total.correct])):.4f}\")\n",
    "\n",
    "    # final_df와 통계행을 합칩니다.\n",
    "    return pd.concat([final_df.reset_index(), temp_total.reset_index()]).groupby(\n",
    "        [\"pair_name\", \"total\"]\n",
    "    ).sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_name = \"gender\"\n",
    "draw_accuracy_table(prop_name, pair_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_name = \"age_group\"\n",
    "draw_accuracy_table(prop_name, pair_list).sort_values('correct').iloc[:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_name = \"category\"\n",
    "draw_accuracy_table(prop_name, pair_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_metric_heatmap(prop_name, pair_list):\n",
    "    kor_prop_name = prop_name_dict[prop_name]\n",
    "\n",
    "    # 한글 폰트 설정\n",
    "    font_name = font_manager.FontProperties(fname=\"/usr/share/fonts/NanumFont/NanumGothicBold.ttf\").get_name()\n",
    "    plt.rc(\"font\", family=font_name)\n",
    "\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(20, 8))\n",
    "\n",
    "    # Compute the global min and max to use for all heatmaps\n",
    "    vmin = float('inf')\n",
    "    vmax = float('-inf')\n",
    "\n",
    "    for sub_task in pair_list:\n",
    "        lr = get_lr(sub_task, prop_name, True)\n",
    "        heatmap_data = (\n",
    "            lr.groupby([f\"{prop_name}_left\", f\"{prop_name}_right\"]).sum().correct\n",
    "            / lr.groupby([f\"{prop_name}_left\", f\"{prop_name}_right\"]).count().correct\n",
    "        )\n",
    "        vmin = min(vmin, heatmap_data.min())\n",
    "        vmax = max(vmax, heatmap_data.max())\n",
    "\n",
    "    pair_name_list = []\n",
    "    copied = None\n",
    "    for i, sub_task in enumerate(pair_list):\n",
    "        lr = get_lr(sub_task, prop_name, True)\n",
    "\n",
    "        # DataFrame을 pivot 형태로 변환\n",
    "        heatmap_data = (\n",
    "            lr.groupby([f\"{prop_name}_left\", f\"{prop_name}_right\"]).sum().correct\n",
    "            / lr.groupby([f\"{prop_name}_left\", f\"{prop_name}_right\"]).count().correct\n",
    "        )\n",
    "        heatmap_data = heatmap_data.reset_index()\n",
    "        heatmap_data = heatmap_data.pivot(f\"{prop_name}_left\", f\"{prop_name}_right\", \"correct\")\n",
    "        if copied is None:\n",
    "            copied = heatmap_data.copy()\n",
    "        # heatmap 그리기\n",
    "        sns.heatmap(heatmap_data, cmap=\"coolwarm\", annot=True, fmt=\".2f\", ax=axs[i], vmin=vmin, vmax=vmax)\n",
    "        # x, y 축 라벨 및 타이틀 설정\n",
    "        axs[i].set_title(f\"[{lr.pair_name}] {kor_prop_name}간 검증 정확도\", fontsize=14)\n",
    "        axs[i].set_xlabel(f\"오른쪽 {kor_prop_name}\", fontsize=12)\n",
    "        axs[i].set_ylabel(f\"왼쪽 {kor_prop_name}\", fontsize=12)\n",
    "        \n",
    "        pair_name_list.append(sub_task.pair_name)\n",
    "    \n",
    "    print(f'Figure | {\"와 \".join(pair_name_list)}의 {kor_prop_name} 검증 정확도')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return copied - heatmap_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_name = \"gender\"\n",
    "draw_metric_heatmap(prop_name, pair_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_name = \"age_group\"\n",
    "draw_metric_heatmap(prop_name, pair_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_name = \"category\"\n",
    "draw_metric_heatmap(prop_name, pair_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import font_manager\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_metric_kde(prop_name, pair_list):\n",
    "    kor_prop_name = prop_name_dict[prop_name]\n",
    "\n",
    "    # 한글 폰트 설정\n",
    "    font_name = font_manager.FontProperties(fname=\"/usr/share/fonts/NanumFont/NanumGothicBold.ttf\").get_name()\n",
    "    plt.rc(\"font\", family=font_name)\n",
    "\n",
    "    sns.set(style=\"whitegrid\")  # setting seaborn style\n",
    "    plt.figure(figsize=(20, 6))  # specifying figure size\n",
    "\n",
    "    # Subplot 1 for lr1\n",
    "    plt.subplot(1, 2, 1)\n",
    "    pair_name_list = []\n",
    "    sub_task = pair_list[0]  # Change this to choose the task\n",
    "    lr = get_lr(sub_task, prop_name)\n",
    "    pair_name_list.append(sub_task.pair_name)    \n",
    "    for tag in lr.total.unique():\n",
    "        sub_frame = lr[lr.total == tag].distance - lr.best_distance\n",
    "        sns.kdeplot(sub_frame, label=tag, fill=True, alpha=0.1)\n",
    "\n",
    "    plt.xlabel(\"거리 차이\", fontsize=14, fontproperties=fontprop)\n",
    "    plt.ylabel(\"밀도\", fontsize=14, fontproperties=fontprop)\n",
    "    plt.title(f\"[{','.join(pair_name_list)}] {kor_prop_name}에 따른 거리 차이의 커널 밀도 추정\", fontsize=16, fontproperties=fontprop)\n",
    "    plt.legend(title=prop_name.capitalize(), title_fontsize=\"13\", fontsize=12)\n",
    "\n",
    "    # Subplot 2 for lr2\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sub_task = pair_list[1]  # Change this to choose the task\n",
    "    lr = get_lr(sub_task, prop_name)\n",
    "    pair_name_list.append(sub_task.pair_name)    \n",
    "    for tag in lr.total.unique():\n",
    "        sub_frame = lr[lr.total == tag].distance - lr.best_distance\n",
    "        sns.kdeplot(sub_frame, label=tag, fill=True, alpha=0.1)\n",
    "        \n",
    "    print(f'Figure | {\"와 \".join(pair_name_list)}의 {kor_prop_name}에 따른 거리 차이의 커널 밀도 추정')\n",
    "\n",
    "    plt.xlabel(\"거리 차이\", fontsize=14, fontproperties=fontprop)\n",
    "    plt.ylabel(\"밀도\", fontsize=14, fontproperties=fontprop)\n",
    "    plt.title(f\"[{','.join(pair_name_list)}] {kor_prop_name}에 따른 거리 차이의 커널 밀도 추정\", fontsize=16, fontproperties=fontprop)\n",
    "    plt.legend(title=prop_name.capitalize(), title_fontsize=\"13\", fontsize=12)\n",
    "    plt.xlim(-15, 15)\n",
    "\n",
    "    # Removing top and right borders\n",
    "    sns.despine()\n",
    "\n",
    "    plt.tight_layout()  # for better layout\n",
    "    plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_name = \"gender\"\n",
    "draw_metric_kde(prop_name, pair_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_name = \"category\"\n",
    "draw_metric_kde(prop_name, pair_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_metric_single_kde(prop_name, pair_list):\n",
    "    sns.set(style=\"whitegrid\")  # setting seaborn style\n",
    "    plt.figure(figsize=(10, 6))  # specifying figure size\n",
    "\n",
    "    pair_name_list = []\n",
    "    for sub_task in pair_list:\n",
    "        lr = get_lr(sub_task, prop_name)\n",
    "        pair_name_list.append(sub_task.pair_name)    \n",
    "        for tag in lr.total.unique():\n",
    "            sub_frame = lr[lr.total == tag].distance - lr.best_distance\n",
    "            sns.kdeplot(sub_frame, label=f\"[{sub_task.pair_name}] {tag}\", fill=True, alpha=0.1)\n",
    "\n",
    "\n",
    "    # Setting labels and title\n",
    "    plt.xlabel(\"거리 차이\", fontsize=14, fontproperties=fontprop)\n",
    "    plt.ylabel(\"밀도\", fontsize=14, fontproperties=fontprop)\n",
    "    plt.title(f\"[{','.join(pair_name_list)}] 거리 차이의 커널 밀도 추정\", fontsize=16, fontproperties=fontprop)\n",
    "    plt.legend(title=prop_name.capitalize(), title_fontsize=\"13\", fontsize=12)\n",
    "    plt.xlim(-15, 15)\n",
    "\n",
    "    # Removing top and right borders\n",
    "    sns.despine()\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_name = \"age_group\"\n",
    "# draw_metric_single_kde(prop_name, pair_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LogNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_metric_scatter(prop_name, pair_list):\n",
    "    # 한글 폰트 설정\n",
    "    font_name = font_manager.FontProperties(\n",
    "        fname=\"/usr/share/fonts/NanumFont/NanumGothicBold.ttf\"\n",
    "    ).get_name()\n",
    "    plt.rc(\"font\", family=font_name)\n",
    "\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(20, 8))\n",
    "\n",
    "    pair_name_list = []\n",
    "    for i, sub_task in enumerate(pair_list):\n",
    "        lr = get_lr(sub_task, prop_name)\n",
    "\n",
    "        # Scatter plot\n",
    "        temp = pd.concat([lr, abs(lr.age_left - lr.age_right)], axis=1)\n",
    "        temp.columns = temp.columns[:-1].append(pd.Index([\"age_diff\"]))\n",
    "        selected = pd.DataFrame(\n",
    "            temp.groupby(\"age_diff\").sum().correct\n",
    "            / temp.groupby(\"age_diff\").count().correct\n",
    "        ).sort_values(by=\"correct\")\n",
    "\n",
    "        # cmap과 norm을 설정하여 데이터의 수에 따라 색상을 조정합니다.\n",
    "        cmap = plt.cm.get_cmap(\"PRGn\")\n",
    "        norm = LogNorm(\n",
    "            vmin=temp.groupby(\"age_diff\").count().correct.min(),\n",
    "            vmax=temp.groupby(\"age_diff\").count().correct.max(),\n",
    "        )\n",
    "\n",
    "        scatter = axs[i].scatter(\n",
    "            selected.index,\n",
    "            selected.correct,\n",
    "            c=temp.groupby(\"age_diff\").count().correct,\n",
    "            cmap=cmap,\n",
    "            norm=norm,\n",
    "            alpha=0.7,\n",
    "        )\n",
    "\n",
    "        # colorbar 추가\n",
    "        cbar = fig.colorbar(scatter, ax=axs[i])\n",
    "        cbar.set_label(\"데이터 수\", rotation=270, labelpad=15, fontsize=10)\n",
    "\n",
    "        # x, y 축 라벨 및 타이틀 설정\n",
    "        axs[i].set_xlabel(\"나이 또는 나이 그룹의 평균 나이 차이(절대값)\", fontsize=12)\n",
    "        axs[i].set_ylabel(\"검증 정확도\", fontsize=12)\n",
    "        axs[i].set_title(f\"[{sub_task.pair_name}] 나이 차이에 따른 검증 정확도\", fontsize=14)\n",
    "        axs[i].set_xlim(0)\n",
    "        axs[i].set_ylim(0.5)\n",
    "        pair_name_list.append(sub_task.pair_name)\n",
    "\n",
    "    print(f'Figure | {\"와 \".join(pair_name_list)}의 나이 차이에 따른 검증 정확도')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_name = \"age\"\n",
    "draw_metric_scatter(prop_name, pair_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
