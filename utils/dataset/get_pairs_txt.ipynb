{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from fpt.data import join_face_df\n",
    "from fpt.split import read_split\n",
    "from fpt.path import DTFR, UTIL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face = join_face_df(DTFR, \"aihub_family\")  # 16.1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_CATEGORY = \"train\"\n",
    "valid_uuids = read_split(TASK_CATEGORY)\n",
    "x_valid = face.loc[valid_uuids]\n",
    "x_valid = x_valid.reset_index().reset_index().set_index(\"uuid\")\n",
    "x_valid.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample group\n",
    "# x_valid.groupby('target').index.apply(list).to_frame().head()\n",
    "# x_valid.groupby(['family_id', 'personal_id', 'category']).index.apply(list).to_frame().head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(22)\n",
    "NUM_FOLDS = 10\n",
    "NUM_PAIRS = 300\n",
    "CATEGORY = \"Age\"\n",
    "target_pair = f\"pairs/{TASK_CATEGORY}/pairs_{CATEGORY}.txt\"\n",
    "os.makedirs(os.path.dirname(target_pair), exist_ok=True)\n",
    "\n",
    "is_family = x_valid.category == CATEGORY\n",
    "family_valid = x_valid[is_family]\n",
    "idx_family_valid = family_valid.groupby(\"target\").index.apply(list).to_frame()\n",
    "\n",
    "with open(target_pair, \"w\") as f:\n",
    "    f.write(f\"{NUM_FOLDS} {NUM_PAIRS}\\n\")\n",
    "    for n in range(NUM_FOLDS):\n",
    "        # matched\n",
    "        matched_sample = idx_family_valid.sample(\n",
    "            n=300, replace=False, random_state=n\n",
    "        ).sort_values(\"target\")\n",
    "        for key, value in matched_sample.iterrows():\n",
    "            idxs = value.loc[\"index\"]\n",
    "            selected = np.random.choice(idxs, size=2, replace=False)\n",
    "            f.write(f\"{key:8s}\\t{valid_uuids[selected[0]]}\\t{valid_uuids[selected[1]]}\")\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "        # mismatched\n",
    "        for i in range(300):\n",
    "            mismatched_sample = idx_family_valid.sample(\n",
    "                n=2, replace=False, random_state=n * 1000 + i\n",
    "            ).sort_values(\"target\")\n",
    "            sampled = [\n",
    "                [key, np.random.choice(value.loc[\"index\"], replace=False)]\n",
    "                for key, value in mismatched_sample.iterrows()\n",
    "            ]\n",
    "            target_a, idx_a, target_b, idx_b = np.array(sampled).flatten().tolist()\n",
    "            uuid_a, uuid_b = valid_uuids[int(idx_a)], valid_uuids[int(idx_b)]\n",
    "            f.write(f\"{target_a:<8}\\t{uuid_a}\\t{target_b:<8}\\t{uuid_b}\")\n",
    "            f.write(\"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get New Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fpt.data import join_face_df\n",
    "from fpt.split import read_split\n",
    "from fpt.path import DTFR\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face = join_face_df(DTFR, \"aihub_family\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_CATEGORY = \"valid\"\n",
    "valid_uuids = read_split(TASK_CATEGORY)\n",
    "x_valid = face.loc[valid_uuids]\n",
    "x_valid = x_valid.reset_index().reset_index().set_index(\"uuid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = x_valid.groupby([\"family_id\", \"age_group\", \"gender\", \"personal_id\"]).agg(list)[\n",
    "    [\"index\"]\n",
    "]\n",
    "\n",
    "# 인덱스 쌍을 저장할 빈 리스트를 생성합니다.\n",
    "index_pairs = []\n",
    "\n",
    "# 각 그룹에 대해 인덱스 쌍을 생성합니다.\n",
    "for _, group in df.groupby([\"family_id\", \"age_group\", \"gender\"]):\n",
    "    index_list = group[\"index\"].tolist()\n",
    "\n",
    "    # 그룹의 인덱스 리스트에 두 개 이상의 원소가 있는 경우에만 조합을 생성합니다.\n",
    "    if len(index_list) >= 2:\n",
    "        for candidate in itertools.combinations(index_list, 2):\n",
    "            for pair in itertools.product(*candidate):\n",
    "                index_pairs.append([*group.index[0][:3], pair])\n",
    "\n",
    "# 인덱스 쌍을 출력합니다.\n",
    "pd.DataFrame(index_pairs, columns=[\"family_id\", \"age_group\", \"gender\", \"pairs\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CASE1: 가족 관계에 있는 얼굴쌍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from fpt.data import join_face_df\n",
    "from fpt.split import read_split\n",
    "from fpt.path import DTFR\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face = join_face_df(DTFR, \"aihub_family\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(22)\n",
    "NUM_FOLDS = 10\n",
    "NUM_PAIRS = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORY = \"CASE1\"\n",
    "TASK_CATEGORY = \"test\"\n",
    "target_pair = f\"pairs/{TASK_CATEGORY}/pairs_{CATEGORY}.txt\"\n",
    "os.makedirs(os.path.dirname(target_pair), exist_ok=True)\n",
    "print(target_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_uuids = read_split(TASK_CATEGORY)\n",
    "x_valid = face.loc[valid_uuids]\n",
    "x_valid = x_valid.reset_index().reset_index().set_index(\"uuid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = x_valid.groupby([\"family_id\", \"personal_id\"]).agg(list)[[\"index\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 그룹에 대해 인덱스 쌍을 생성합니다.\n",
    "total_matched_list = []\n",
    "for index, value in df.itertuples():\n",
    "    for candidate in itertools.combinations(value, 2):\n",
    "        total_matched_list.append([index[0], candidate])\n",
    "total_matched_pairs = pd.DataFrame(total_matched_list, columns=[\"family_id\", \"pairs\"])\n",
    "selected_matched_pairs = total_matched_pairs.sample(\n",
    "    n=3000, replace=False, random_state=22\n",
    ")\n",
    "\n",
    "# 인덱스 쌍을 저장할 빈 리스트를 생성합니다.\n",
    "total_mismatched_list = []\n",
    "\n",
    "# 각 그룹에 대해 인덱스 쌍을 생성합니다.\n",
    "for _, group in df.groupby([\"family_id\"]):\n",
    "    index_list = group[\"index\"].tolist()\n",
    "\n",
    "    # 그룹의 인덱스 리스트에 두 개 이상의 원소가 있는 경우에만 조합을 생성합니다.\n",
    "    if len(index_list) >= 2:\n",
    "        for candidate in itertools.combinations(index_list, 2):\n",
    "            for pair in itertools.product(*candidate):\n",
    "                total_mismatched_list.append([*group.index[0][:1], pair])\n",
    "\n",
    "# 인덱스 쌍을 출력합니다.\n",
    "total_mismatched_pairs = pd.DataFrame(\n",
    "    total_mismatched_list, columns=[\"family_id\", \"pairs\"]\n",
    ")\n",
    "selected_mismatched_pairs = total_mismatched_pairs.sample(\n",
    "    n=3000, replace=False, random_state=22\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_matched = [\n",
    "    group\n",
    "    for _, group in selected_matched_pairs.groupby(\n",
    "        np.arange(len(selected_matched_pairs)) // NUM_PAIRS\n",
    "    )\n",
    "]\n",
    "dfs_mismatched = [\n",
    "    group\n",
    "    for _, group in selected_mismatched_pairs.groupby(\n",
    "        np.arange(len(selected_mismatched_pairs)) // NUM_PAIRS\n",
    "    )\n",
    "]\n",
    "\n",
    "with open(target_pair, \"w\") as f:\n",
    "    f.write(f\"{NUM_FOLDS} {NUM_PAIRS}\\n\")\n",
    "    for df_matched, df_mismatched in zip(dfs_matched, dfs_mismatched):\n",
    "        for row in df_matched.itertuples():\n",
    "            idx1, idx2 = row.pairs\n",
    "            target = x_valid.iloc[idx1].target\n",
    "            assert target == x_valid.iloc[idx2].target\n",
    "            name1 = x_valid.iloc[idx1].name\n",
    "            name2 = x_valid.iloc[idx2].name\n",
    "            f.write(f\"{target:8s}\\t{name1}\\t{name2}\\n\")\n",
    "\n",
    "        for row in df_mismatched.itertuples():\n",
    "            idx1, idx2 = row.pairs\n",
    "            target1 = x_valid.iloc[idx1].target\n",
    "            target2 = x_valid.iloc[idx2].target\n",
    "            assert x_valid.iloc[idx1].family_id == x_valid.iloc[idx2].family_id\n",
    "            assert target1 != target2\n",
    "            name1 = x_valid.iloc[idx1].name\n",
    "            name2 = x_valid.iloc[idx2].name\n",
    "            f.write(f\"{target1:8s}\\t{name1}\\t{target2:8s}\\t{name2}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CASE1C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORY = \"CASE1C\"\n",
    "DIR_CATEGORY = \"test\"\n",
    "TASK_CATEGORY = \"test\"\n",
    "\n",
    "target_pair = f\"pairs/{DIR_CATEGORY}/pairs_{CATEGORY}.txt\"\n",
    "os.makedirs(os.path.dirname(target_pair), exist_ok=True)\n",
    "print(target_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(22)\n",
    "unique_family_id = x_valid.family_id.unique()\n",
    "unique_family_id_total_pairs = list(combinations(unique_family_id, 2))\n",
    "index_list = np.random.choice(len(unique_family_id_total_pairs), 6000, replace=True)\n",
    "selected_family_pairs = np.array(unique_family_id_total_pairs)[index_list]\n",
    "with open(target_pair, \"w\") as f:\n",
    "    f.write(f\"{NUM_FOLDS} {NUM_PAIRS}\\n\")\n",
    "    for fids in selected_family_pairs:\n",
    "\n",
    "        def get_target_and_name(family_id, df=x_valid):\n",
    "            row = df[df.family_id == family_id].sample()\n",
    "            target, name = row.target.item(), row.iloc[0].name\n",
    "            return target, name\n",
    "\n",
    "        fid1, fid2 = fids\n",
    "        target1, name1 = get_target_and_name(fid1)\n",
    "        target2, name2 = get_target_and_name(fid2)\n",
    "        f.write(f\"{target1:8s}\\t{name1}\\t{target2:8s}\\t{name2}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pairs/test/pairs_CASE1C.txt`\n",
    "```markdown\n",
    "10 300\n",
    "F0836-M \t7649eabb-da97-4bd6-9e66-adeee88c69cc\tF0900-D \ted80801a-5c34-4a6a-bb8f-20deb0ca9ca4\n",
    "F0891-S \t749c628a-cb31-4179-9b26-19ccfa5f6018\tF0895-D \te3cfbe54-71d4-461c-861e-bb058ed594c9\n",
    "F0804-D \t9d5d61c5-f8d9-485c-a912-f156e27ebc3f\tF0867-S3\tf94cd228-762b-4e0c-a3ce-a50eff6cb049\n",
    "F0873-M \t6dc0dfb0-52c6-40ee-9f44-fb7a546560fc\tF0889-D \t326b1e97-d796-4af9-982d-7ec73bff9c10\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CASE2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from fpt.data import join_face_df\n",
    "from fpt.split import read_split\n",
    "from fpt.path import DTFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face = join_face_df(DTFR, \"aihub_family\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FOLDS = 10\n",
    "NUM_PAIRS = 300\n",
    "CATEGORY = \"CASE2\"\n",
    "DIR_CATEGORY = \"temp\"\n",
    "TASK_CATEGORY = \"test\"\n",
    "\n",
    "target_pair = f\"pairs/{DIR_CATEGORY}/pairs_{CATEGORY}.txt\"\n",
    "os.makedirs(os.path.dirname(target_pair), exist_ok=True)\n",
    "print(target_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_uuids = read_split(TASK_CATEGORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid = face.loc[valid_uuids]\n",
    "x_valid = x_valid.reset_index().reset_index().set_index(\"uuid\")\n",
    "df = x_valid.groupby([\"target\", \"age_group\"]).agg(list)[['index']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_same_age_list = []  # 52310\n",
    "for index, value in df.itertuples():\n",
    "    for candidate in itertools.combinations(value, 2):\n",
    "        total_same_age_list.append([*index, candidate])\n",
    "        \n",
    "total_same_age_pairs = pd.DataFrame(total_same_age_list, columns=[\"family_id\", \"age_group\", \"pairs\"])\n",
    "selected_same_age_pairs = total_same_age_pairs.sample(\n",
    "    n=6000, replace=False, random_state=22\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAME personal_id & SAME age_group\n",
    "with open(target_pair, \"w\") as f:\n",
    "    f.write(f\"{NUM_FOLDS} {NUM_PAIRS}\\n\")\n",
    "    for row in selected_same_age_pairs.itertuples():\n",
    "        idx1, idx2 = row.pairs\n",
    "        target = x_valid.iloc[idx1].target\n",
    "        age_group = x_valid.iloc[idx1].age_group\n",
    "        assert age_group == x_valid.iloc[idx2].age_group\n",
    "        name1 = x_valid.iloc[idx1].name\n",
    "        name2 = x_valid.iloc[idx2].name\n",
    "        f.write(f\"{target:8s}\\t{name1}\\t{name2}\\n\")\n",
    "        # break\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CASE2C:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FOLDS = 10\n",
    "NUM_PAIRS = 300\n",
    "CATEGORY = \"CASE2C\"\n",
    "DIR_CATEGORY = \"temp\"\n",
    "TASK_CATEGORY = \"test\"\n",
    "\n",
    "target_pair = f\"pairs/{DIR_CATEGORY}/pairs_{CATEGORY}.txt\"\n",
    "os.makedirs(os.path.dirname(target_pair), exist_ok=True)\n",
    "print(target_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인덱스 쌍을 저장할 빈 리스트를 생성합니다.\n",
    "total_mismatched_list = []\n",
    "\n",
    "# 각 그룹에 대해 인덱스 쌍을 생성합니다.\n",
    "for _, group in df.groupby([\"target\"]):\n",
    "    index_list = group[\"index\"].tolist()\n",
    "    # 그룹의 인덱스 리스트에 두 개 이상의 원소가 있는 경우에만 조합을 생성합니다.\n",
    "    if len(index_list) >= 2:\n",
    "        for candidate in itertools.combinations(index_list, 2):\n",
    "            for pair in itertools.product(*candidate):\n",
    "                total_mismatched_list.append([*group.index[0][:1], pair])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인덱스 쌍을 출력합니다.\n",
    "total_mismatched_pairs = pd.DataFrame(\n",
    "    total_mismatched_list, columns=[\"target\", \"pairs\"]\n",
    ")\n",
    "selected_mismatched_pairs = total_mismatched_pairs.sample(\n",
    "    n=6000, replace=False, random_state=22\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(target_pair, \"w\") as f:\n",
    "    f.write(f\"{NUM_FOLDS} {NUM_PAIRS}\\n\")\n",
    "    for row in selected_mismatched_pairs.itertuples():\n",
    "        idx1, idx2 = row.pairs\n",
    "        target1 = x_valid.iloc[idx1].target\n",
    "        target2 = x_valid.iloc[idx2].target\n",
    "        assert x_valid.iloc[idx1].age_group != x_valid.iloc[idx2].age_group\n",
    "        assert target1 == target2\n",
    "        name1 = x_valid.iloc[idx1].name\n",
    "        name2 = x_valid.iloc[idx2].name\n",
    "        f.write(f\"{target1:8s}\\t{name1}\\t{name2}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd \"/home/jupyter/family-photo-tree\"\n",
    "%pwd\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.modules.distance import PairwiseDistance\n",
    "from fpt.path import DATA\n",
    "from fpt.model import Model\n",
    "from fpt.config import cfg\n",
    "from fpt.dataset import AIHubDataset\n",
    "from fpt.logger import initialize_wandb\n",
    "from fpt.utils import log_verification_output\n",
    "from fpt.transform import aihub_valid_transforms\n",
    "from facenet.validate_aihub import validate_aihub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logger\n",
    "wandb_logger = initialize_wandb(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_task = \"CASE1C\"\n",
    "checkpoint = \"230529_0140\"\n",
    "best_distance = 28.465\n",
    "cfg.project_name = \"log_test_validation\"\n",
    "\n",
    "# dataloader\n",
    "aihub_pairs_case1c_dataset = AIHubDataset(\n",
    "    dir=DATA / \"face-image/test_aihub_family\",\n",
    "    pairs_path=DATA / f\"pairs/test/pairs_{validate_task.upper()}.txt\",\n",
    "    transform=aihub_valid_transforms,\n",
    ")\n",
    "test_loader = DataLoader(aihub_pairs_case1c_dataset, batch_size=32)\n",
    "\n",
    "# model\n",
    "model = Model(cfg)\n",
    "model_path = f\"/home/jongphago/family-photo-tree/work_dirs/aihub_r50_onegpu/{checkpoint}_ArcFace/model.pt\"\n",
    "model.load_embedding(path=model_path)\n",
    "\n",
    "# distance_metric\n",
    "l2_distance = PairwiseDistance(p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = 0\n",
    "for a, b, label in tqdm(test_loader):\n",
    "    output_a = model.embedding(a.cuda())\n",
    "    output_b = model.embedding(b.cuda())\n",
    "    distance = l2_distance.forward(output_a, output_b)  # Euclidean distance\n",
    "    result = torch.eq(distance.cpu().detach() < best_distance, label)\n",
    "    out += result.sum().detach()\n",
    "\n",
    "print(f\"{out / len(test_loader.dataset):4.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_output = validate_aihub(\n",
    "    model.embedding, test_loader, \"r50\", 1, task=validate_task\n",
    ")\n",
    "log_verification_output(validate_output, wandb_logger, validate_task.capitalize(), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
