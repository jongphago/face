{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dual-Task"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DT | Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "from arcface_torch.configs.aihub_r50_onegpu import config as aihub_config\n",
    "from arcface_torch.configs.base import config as cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.update(aihub_config)\n",
    "cfg.output = \"work_dirs/aihub_r50_onegpu\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DT | transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "image_size = 112\n",
    "aihub_mean = [0.5444, 0.4335, 0.3800]\n",
    "aihub_std = [0.2672, 0.2295, 0.2156]\n",
    "\n",
    "nia_train_transforms = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.ToPILImage(),\n",
    "        torchvision.transforms.RandomApply(\n",
    "            [\n",
    "                torchvision.transforms.RandomAffine(degrees=10, shear=16),\n",
    "                torchvision.transforms.RandomHorizontalFlip(p=1.0),\n",
    "            ],\n",
    "            p=0.5,\n",
    "        ),\n",
    "        torchvision.transforms.Resize((256, 256)),\n",
    "        torchvision.transforms.RandomCrop((224, 224)),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "nia_valid_transforms = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.ToPILImage(),\n",
    "        torchvision.transforms.Resize((224, 224)),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "aihub_train_transforms = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.Resize(size=(image_size, image_size)),\n",
    "        torchvision.transforms.RandomHorizontalFlip(),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(mean=aihub_mean, std=aihub_std),\n",
    "    ]\n",
    ")\n",
    "\n",
    "aihub_valid_transforms = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.Resize(size=(image_size, image_size)),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(mean=aihub_mean, std=aihub_std),\n",
    "    ]\n",
    ")\n",
    "\n",
    "aihub_test_transforms = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.Resize(size=(image_size, image_size)),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(mean=aihub_mean, std=aihub_std),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DT | AIHub DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fpt.path import DTFR\n",
    "from fpt.data import join_face_df\n",
    "\n",
    "face_df = join_face_df(DTFR, \"aihub_family\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DT | Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from easydict import EasyDict as edict\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from facenet.datasets.AIHubDataset import AIHubDataset\n",
    "from nia_age.data import NiaDataset as nia\n",
    "\n",
    "RANGE_TO_MEDIAN = nia.RANGE_TO_MEDIAN\n",
    "AGE_GROUPS = nia.AGE_GROUPS\n",
    "GROUP_TO_INDEX = {group: index for index, group in enumerate(AGE_GROUPS)}\n",
    "age_to_age_groups = nia.age_to_age_groups\n",
    "\n",
    "\n",
    "class FaceAgeDataset(Dataset):\n",
    "    def __init__(self, root_dir, face_df, transform):\n",
    "        super(FaceAgeDataset, self).__init__()\n",
    "        self.face_dataset = ImageFolder(root=root_dir, transform=transform)\n",
    "        self.face_df = face_df\n",
    "        self.class_to_idx = self.face_dataset.class_to_idx\n",
    "        self.samples = self.face_dataset.samples  # 이 줄을 추가합니다.\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.face_dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image, face_label = self.face_dataset[index]\n",
    "        path, _ = self.face_dataset.samples[index]\n",
    "        *_, key = os.path.splitext(path)[0].split(\"/\")\n",
    "        row = face_df.loc[key]\n",
    "        sample = edict(\n",
    "            {\n",
    "                \"image\": image,\n",
    "                \"age\": row.age,\n",
    "                \"age_class\": GROUP_TO_INDEX[row.age_group],\n",
    "                \"file\": path,\n",
    "                \"data_type\": row.category,\n",
    "                \"family_id\": row.family_id,\n",
    "                \"personal_id\": row.target,\n",
    "                \"face_label\": face_label,\n",
    "                \"key\": key,\n",
    "            }\n",
    "        )\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_age_train_dataset = FaceAgeDataset(\n",
    "    root_dir=\"/home/jupyter/data/face-image/train_aihub_family\",\n",
    "    face_df=face_df,\n",
    "    transform=aihub_train_transforms,\n",
    ")\n",
    "\n",
    "face_age_valid_dataset = FaceAgeDataset(\n",
    "    root_dir=\"/home/jupyter/data/face-image/valid_aihub_family\",\n",
    "    face_df=face_df,\n",
    "    transform=aihub_valid_transforms,\n",
    ")\n",
    "\n",
    "face_age_test_dataset = FaceAgeDataset(\n",
    "    root_dir=\"/home/jupyter/data/face-image/test_aihub_family\",\n",
    "    face_df=face_df,\n",
    "    transform=aihub_test_transforms,\n",
    ")\n",
    "\n",
    "aihub_pairs_valid_dataset = AIHubDataset(\n",
    "    dir=\"/home/jupyter/data/face-image/valid_aihub_family\",\n",
    "    pairs_path=\"/home/jupyter/data/pairs/valid/pairs_Age.txt\",\n",
    "    transform=aihub_valid_transforms,\n",
    ")\n",
    "\n",
    "aihub_pairs_test_dataset = AIHubDataset(\n",
    "    dir=\"/home/jupyter/data/face-image/test_aihub_family\",\n",
    "    pairs_path=\"/home/jupyter/data/pairs/test/pairs_Age.txt\",\n",
    "    transform=aihub_valid_transforms,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DT | DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_batch_size = 16\n",
    "valid_batch_size = 1\n",
    "test_batch_size = 1\n",
    "\n",
    "face_age_train_loader = DataLoader(\n",
    "    face_age_train_dataset,\n",
    "    batch_size=train_batch_size,\n",
    "    num_workers=0,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "face_age_valid_loader = DataLoader(\n",
    "    face_age_valid_dataset,\n",
    "    batch_size=valid_batch_size,\n",
    "    num_workers=0,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "face_age_test_loader = DataLoader(\n",
    "    face_age_test_dataset,\n",
    "    batch_size=test_batch_size,\n",
    "    num_workers=0,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "aihub_pairs_valid_loader = DataLoader(\n",
    "    aihub_pairs_valid_dataset,\n",
    "    batch_size=valid_batch_size,\n",
    "    num_workers=0,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "aihub_pairs_test_loader = DataLoader(\n",
    "    aihub_pairs_test_dataset,\n",
    "    batch_size=test_batch_size,\n",
    "    num_workers=0,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DT | Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.nn.functional import normalize, linear\n",
    "from arcface_torch.losses import CombinedMarginLoss, ArcFace, CosFace\n",
    "from nia_age.mean_variance_loss import MeanVarianceLoss\n",
    "from nia_age.main_ae import LAMBDA_1, LAMBDA_2, START_AGE, END_AGE\n",
    "\n",
    "\n",
    "NUM_CLASSES = (\n",
    "    len(face_age_train_dataset.class_to_idx) if face_age_train_dataset else 2154\n",
    ")\n",
    "\n",
    "\n",
    "class FaceFC(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        margin_loss: Callable,\n",
    "        embedding_size: int,\n",
    "        num_classes: int,\n",
    "    ):\n",
    "        super(FaceFC, self).__init__()\n",
    "        self.cross_entropy = CrossEntropyLoss()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.weight = torch.nn.Parameter(\n",
    "            torch.normal(0, 0.01, (1, embedding_size))\n",
    "        )\n",
    "        self.margin_softmax = margin_loss\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        embeddings: torch.Tensor,\n",
    "        labels: torch.Tensor,\n",
    "    ):\n",
    "        # labels\n",
    "        labels.squeeze_()\n",
    "        labels = labels.long()\n",
    "        labels = labels.view(-1, 1)\n",
    "\n",
    "        # embeddings\n",
    "        norm_embeddings = normalize(embeddings)\n",
    "\n",
    "        # weight\n",
    "        weight = torch.nn.Parameter(\n",
    "            torch.normal(0, 0.01, (self.num_classes, 512))\n",
    "        ).cuda()\n",
    "        norm_weight_activated = normalize(weight)\n",
    "        norm_weight_activated.shape\n",
    "\n",
    "        # logits\n",
    "        logits = linear(norm_embeddings, norm_weight_activated)\n",
    "        logits = logits.clamp(-1, 1)\n",
    "\n",
    "        # softmax\n",
    "        softmax = self.margin_loss(logits, labels)\n",
    "\n",
    "        # loss\n",
    "        loss = self.cross_entropy(softmax, labels.flatten())\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "margin_loss = CombinedMarginLoss(\n",
    "    64,\n",
    "    *cfg.margin_list,\n",
    "    cfg.interclass_filtering_threshold,\n",
    ")\n",
    "\n",
    "face_fc = FaceFC(\n",
    "    margin_loss,\n",
    "    512,\n",
    "    NUM_CLASSES,\n",
    ")\n",
    "\n",
    "mean_variance_loss = MeanVarianceLoss(\n",
    "    LAMBDA_1,\n",
    "    LAMBDA_2,\n",
    "    START_AGE,\n",
    "    END_AGE,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
