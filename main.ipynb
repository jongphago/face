{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dual-Task"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DT | Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "from arcface_torch.configs.aihub_r50_onegpu import config as aihub_config\n",
    "from arcface_torch.configs.base import config as cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.update(aihub_config)\n",
    "cfg.output = \"work_dirs/aihub_r50_onegpu\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DT | transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "image_size = 112\n",
    "aihub_mean = [0.5444, 0.4335, 0.3800]\n",
    "aihub_std = [0.2672, 0.2295, 0.2156]\n",
    "\n",
    "nia_train_transforms = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.ToPILImage(),\n",
    "        torchvision.transforms.RandomApply(\n",
    "            [\n",
    "                torchvision.transforms.RandomAffine(degrees=10, shear=16),\n",
    "                torchvision.transforms.RandomHorizontalFlip(p=1.0),\n",
    "            ],\n",
    "            p=0.5,\n",
    "        ),\n",
    "        torchvision.transforms.Resize((256, 256)),\n",
    "        torchvision.transforms.RandomCrop((224, 224)),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "nia_valid_transforms = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.ToPILImage(),\n",
    "        torchvision.transforms.Resize((224, 224)),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "aihub_train_transforms = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.Resize(size=(image_size, image_size)),\n",
    "        torchvision.transforms.RandomHorizontalFlip(),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(mean=aihub_mean, std=aihub_std),\n",
    "    ]\n",
    ")\n",
    "\n",
    "aihub_valid_transforms = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.Resize(size=(image_size, image_size)),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(mean=aihub_mean, std=aihub_std),\n",
    "    ]\n",
    ")\n",
    "\n",
    "aihub_test_transforms = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.Resize(size=(image_size, image_size)),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(mean=aihub_mean, std=aihub_std),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DT | AIHub DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fpt.path import DTFR\n",
    "from fpt.data import join_face_df\n",
    "\n",
    "face_df = join_face_df(DTFR, \"aihub_family\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DT | Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from easydict import EasyDict as edict\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from facenet.datasets.AIHubDataset import AIHubDataset\n",
    "from nia_age.data import NiaDataset as nia\n",
    "\n",
    "RANGE_TO_MEDIAN = nia.RANGE_TO_MEDIAN\n",
    "AGE_GROUPS = nia.AGE_GROUPS\n",
    "GROUP_TO_INDEX = {group: index for index, group in enumerate(AGE_GROUPS)}\n",
    "TRAIN_FID_TO_INDEX = {idx: f\"F{i:04d}\" for idx, i in enumerate(range(1, 701))}\n",
    "age_to_age_groups = nia.age_to_age_groups\n",
    "\n",
    "\n",
    "class FaceAgeDataset(Dataset):\n",
    "    def __init__(self, root_dir, face_df, transform):\n",
    "        super(FaceAgeDataset, self).__init__()\n",
    "        self.face_dataset = ImageFolder(root=root_dir, transform=transform)\n",
    "        self.face_df = face_df\n",
    "        self.class_to_idx = self.face_dataset.class_to_idx\n",
    "        self.samples = self.face_dataset.samples\n",
    "        uuids = [\n",
    "            img_path.rsplit(\".\", 1)[0].rsplit(\"/\", 1)[1] for img_path, _ in self.samples\n",
    "        ]\n",
    "        unique_family_id = self.face_df.loc[uuids].family_id.unique()\n",
    "        self.FID_TO_INDEX = {\n",
    "            id: index for index, id in enumerate(sorted(unique_family_id))\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.face_dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image, face_label = self.face_dataset[index]\n",
    "        path, _ = self.face_dataset.samples[index]\n",
    "        *_, key = os.path.splitext(path)[0].split(\"/\")\n",
    "        row = face_df.loc[key]\n",
    "        sample = edict(\n",
    "            {\n",
    "                \"image\": image,\n",
    "                \"age\": row.age,\n",
    "                \"age_class\": GROUP_TO_INDEX[row.age_group],\n",
    "                \"file\": path,\n",
    "                \"data_type\": row.category,\n",
    "                \"family_id\": row.family_id,\n",
    "                \"family_class\": self.FID_TO_INDEX[row.family_id],\n",
    "                \"personal_id\": row.target,\n",
    "                \"face_label\": face_label,\n",
    "                \"key\": key,\n",
    "            }\n",
    "        )\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_age_train_dataset = FaceAgeDataset(\n",
    "    root_dir=\"/home/jupyter/data/face-image/train_aihub_family\",\n",
    "    face_df=face_df,\n",
    "    transform=aihub_train_transforms,\n",
    ")\n",
    "\n",
    "face_age_valid_dataset = FaceAgeDataset(\n",
    "    root_dir=\"/home/jupyter/data/face-image/valid_aihub_family\",\n",
    "    face_df=face_df,\n",
    "    transform=aihub_valid_transforms,\n",
    ")\n",
    "\n",
    "face_age_test_dataset = FaceAgeDataset(\n",
    "    root_dir=\"/home/jupyter/data/face-image/test_aihub_family\",\n",
    "    face_df=face_df,\n",
    "    transform=aihub_test_transforms,\n",
    ")\n",
    "\n",
    "aihub_pairs_valid_dataset = AIHubDataset(\n",
    "    dir=\"/home/jupyter/data/face-image/valid_aihub_family\",\n",
    "    pairs_path=\"/home/jupyter/data/pairs/valid/pairs_Age.txt\",\n",
    "    transform=aihub_valid_transforms,\n",
    ")\n",
    "\n",
    "aihub_pairs_test_dataset = AIHubDataset(\n",
    "    dir=\"/home/jupyter/data/face-image/test_aihub_family\",\n",
    "    pairs_path=\"/home/jupyter/data/pairs/test/pairs_Age.txt\",\n",
    "    transform=aihub_valid_transforms,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DT | DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_batch_size = 32\n",
    "valid_batch_size = 1\n",
    "test_batch_size = 1\n",
    "\n",
    "face_age_train_loader = DataLoader(\n",
    "    face_age_train_dataset,\n",
    "    batch_size=train_batch_size,\n",
    "    num_workers=0,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "face_age_valid_loader = DataLoader(\n",
    "    face_age_valid_dataset,\n",
    "    batch_size=valid_batch_size,\n",
    "    num_workers=0,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "face_age_test_loader = DataLoader(\n",
    "    face_age_test_dataset,\n",
    "    batch_size=test_batch_size,\n",
    "    num_workers=0,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "aihub_pairs_valid_loader = DataLoader(\n",
    "    aihub_pairs_valid_dataset,\n",
    "    batch_size=valid_batch_size,\n",
    "    num_workers=0,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "aihub_pairs_test_loader = DataLoader(\n",
    "    aihub_pairs_test_dataset,\n",
    "    batch_size=test_batch_size,\n",
    "    num_workers=0,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DT | Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.nn.functional import normalize, linear\n",
    "from arcface_torch.losses import CombinedMarginLoss, ArcFace, CosFace\n",
    "from nia_age.mean_variance_loss import MeanVarianceLoss\n",
    "from nia_age.main_ae import LAMBDA_1, LAMBDA_2, START_AGE, END_AGE\n",
    "\n",
    "\n",
    "NUM_CLASSES = (\n",
    "    len(face_age_train_dataset.class_to_idx) if face_age_train_dataset else 2154\n",
    ")\n",
    "\n",
    "\n",
    "class FaceRecogFC(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        margin_loss: Callable,\n",
    "        embedding_size: int,\n",
    "        num_classes: int,\n",
    "    ):\n",
    "        super(FaceRecogFC, self).__init__()\n",
    "        self.cross_entropy = CrossEntropyLoss()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.weight = torch.nn.Parameter(torch.normal(0, 0.01, (1, embedding_size)))\n",
    "        self.margin_loss = margin_loss\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        embeddings: torch.Tensor,\n",
    "        labels: torch.Tensor,\n",
    "    ):\n",
    "        # labels\n",
    "        labels.squeeze_()\n",
    "        labels = labels.long()\n",
    "        labels = labels.view(-1, 1)\n",
    "\n",
    "        # embeddings\n",
    "        norm_embeddings = normalize(embeddings)\n",
    "\n",
    "        # weight\n",
    "        weight = torch.nn.Parameter(\n",
    "            torch.normal(0, 0.01, (self.num_classes, 512))\n",
    "        ).cuda()\n",
    "        norm_weight_activated = normalize(weight)\n",
    "        norm_weight_activated.shape\n",
    "\n",
    "        # logits\n",
    "        logits = linear(norm_embeddings, norm_weight_activated)\n",
    "        logits = logits.clamp(-1, 1)\n",
    "\n",
    "        # softmax\n",
    "        softmax = self.margin_loss(logits, labels)\n",
    "\n",
    "        # loss\n",
    "        loss = self.cross_entropy(softmax, labels.flatten())\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "margin_loss = CombinedMarginLoss(\n",
    "    64,\n",
    "    *cfg.margin_list,\n",
    "    cfg.interclass_filtering_threshold,\n",
    ")\n",
    "\n",
    "face_recog_fc = FaceRecogFC(\n",
    "    margin_loss,\n",
    "    512,\n",
    "    NUM_CLASSES,\n",
    ")\n",
    "\n",
    "mean_variance_loss = MeanVarianceLoss(\n",
    "    LAMBDA_1,\n",
    "    LAMBDA_2,\n",
    "    START_AGE,\n",
    "    END_AGE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import distributed\n",
    "from arcface_torch.partial_fc_v2 import PartialFC_V2\n",
    "from arcface_torch.losses import CombinedMarginLoss\n",
    "\n",
    "if not distributed.is_initialized():\n",
    "    try:\n",
    "        rank = int(os.environ[\"RANK\"])\n",
    "        local_rank = int(os.environ[\"LOCAL_RANK\"])\n",
    "        world_size = int(os.environ[\"WORLD_SIZE\"])\n",
    "        distributed.init_process_group(\"nccl\")\n",
    "        \n",
    "    except KeyError:\n",
    "        rank = 0\n",
    "        local_rank = 0\n",
    "        world_size = 1\n",
    "        distributed.init_process_group(\n",
    "            backend=\"nccl\",\n",
    "            init_method=\"tcp://127.0.0.1:12584\",\n",
    "            rank=rank,\n",
    "            world_size=world_size,\n",
    "        )\n",
    "        \n",
    "margin_loss = CombinedMarginLoss(\n",
    "    64,\n",
    "    *cfg.margin_list,\n",
    "    cfg.interclass_filtering_threshold,\n",
    ")\n",
    "\n",
    "module_partial_fc = PartialFC_V2(\n",
    "    margin_loss,\n",
    "    cfg.embedding_size,\n",
    "    cfg.num_classes,\n",
    "    cfg.sample_rate,\n",
    "    cfg.fp16,\n",
    ")\n",
    "\n",
    "module_partial_fc.train().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def age_loss_func(age_pred, age_group_pred, sample, mean_variance_loss, criterion):\n",
    "    dta = np.array(sample.data_type)\n",
    "    age_sample_indices = dta != \"Age\"\n",
    "    age_pred = age_pred[age_sample_indices]\n",
    "    labels = sample.age[age_sample_indices].cuda()\n",
    "\n",
    "    mean_loss, variance_loss = mean_variance_loss(age_pred, labels)\n",
    "    age_softmax_loss = criterion(age_pred, labels)\n",
    "    mean_loss, variance_loss, age_softmax_loss\n",
    "\n",
    "    age_group_pred = age_group_pred[~age_sample_indices]\n",
    "    age_group_labels = sample.age_class[~age_sample_indices].cuda()\n",
    "    age_group_softmax_loss = criterion(age_group_pred, age_group_labels)\n",
    "    return age_softmax_loss, age_group_softmax_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def kinship_loss_func(kinship_pred, sample, criterion):\n",
    "    labels = sample.family_class.cuda()\n",
    "    kinship_softmax_loss = criterion(kinship_pred, labels)\n",
    "    return kinship_softmax_loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DT | Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from arcface_torch.backbones import get_model\n",
    "from nia_age.main_ae import AgeModel\n",
    "from nia_age.main_ae import START_AGE, END_AGE, NUM_AGE_GROUPS\n",
    "\n",
    "network = \"r50\"\n",
    "NUM_AGES = END_AGE - START_AGE + 1\n",
    "\n",
    "face_age_model = get_model(network, dropout=0.0)\n",
    "face_age_path = f\"/home/jupyter/family-photo-tree/utils/model/arcface/{network}/backbone.pth\"\n",
    "face_age_model.load_state_dict(torch.load(face_age_path))\n",
    "\n",
    "nia_age_model = AgeModel(NUM_AGES, NUM_AGE_GROUPS)\n",
    "nia_age_path = \"/home/jongphago/nia_age/result_model/model_0\"\n",
    "nia_age_model.load_state_dict(torch.load(nia_age_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgeModule(nn.Module):\n",
    "    def __init__(self, num_ages, num_age_groups):\n",
    "        super(AgeModule, self).__init__()\n",
    "        self.age_classifier = nn.Linear(512, num_ages)\n",
    "        self.age_group_classifier = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_age_groups),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        age_pred = self.age_classifier(x)\n",
    "        age_group_pred = self.age_group_classifier(x)\n",
    "        return age_pred, age_group_pred\n",
    "\n",
    "\n",
    "age_module = AgeModule(NUM_AGES, NUM_AGE_GROUPS)\n",
    "saved_params = torch.load(nia_age_path)\n",
    "selected_params = {\n",
    "    k: v\n",
    "    for k, v in saved_params.items()\n",
    "    if \"age_classifier\" in k or \"age_group_classifier\" in k\n",
    "}\n",
    "age_module.load_state_dict(selected_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KinshipModule(nn.Module):\n",
    "    def __init__(self, num_family_id):\n",
    "        super(KinshipModule, self).__init__()\n",
    "        self.kinship_classifier = nn.Linear(512, num_family_id)\n",
    "\n",
    "    def forward(self, x):\n",
    "        kinship_pred = self.kinship_classifier(x)\n",
    "        return kinship_pred\n",
    "\n",
    "\n",
    "NUM_TRAIN_FAMILY = 700\n",
    "kinship_module = KinshipModule(NUM_TRAIN_FAMILY)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DT | Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD\n",
    "from arcface_torch.lr_scheduler import PolyScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "momentum = 0.9  #\n",
    "weight_decay = 5e-4  #\n",
    "lr = 0.02\n",
    "\n",
    "face_age_optimizer = SGD(\n",
    "    params=[\n",
    "        {\"params\": face_age_model.parameters()},\n",
    "        {\"params\": module_partial_fc.parameters()},\n",
    "        {\"params\": kinship_module.parameters()}\n",
    "    ],\n",
    "    lr=lr,\n",
    "    momentum=momentum,\n",
    "    weight_decay=weight_decay,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 2\n",
    "world_size = 1\n",
    "cfg.total_batch_size = cfg.batch_size * world_size\n",
    "cfg.warmup_step = cfg.num_image // cfg.total_batch_size * cfg.warmup_epoch\n",
    "cfg.total_step = cfg.num_image // cfg.total_batch_size * num_epoch\n",
    "\n",
    "lr_scheduler = PolyScheduler(\n",
    "    optimizer=face_age_optimizer,\n",
    "    base_lr=lr,\n",
    "    max_steps=cfg.total_step,  # 1452\n",
    "    warmup_steps=cfg.warmup_step,\n",
    "    last_epoch=-1,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DT | Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_to_int(x):\n",
    "    return x.cpu().data.numpy().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_age_model.train()\n",
    "face_age_model.cuda()\n",
    "age_module.train()\n",
    "age_module.cuda()\n",
    "kinship_module.train()\n",
    "kinship_module.cuda()\n",
    "module_partial_fc.train()\n",
    "module_partial_fc.cuda()\n",
    "mean_variance_loss.train()\n",
    "mean_variance_loss.cuda()\n",
    "cross_entropy_loss = CrossEntropyLoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, sample in enumerate(face_age_train_loader):\n",
    "    embeddings = face_age_model(sample.image.cuda())\n",
    "\n",
    "    age_pred, age_group_pred = age_module(embeddings)\n",
    "\n",
    "    fr_loss: torch.Tensor = module_partial_fc(embeddings, sample.face_label.cuda())\n",
    "    age_loss, age_group_loss = age_loss_func(\n",
    "        age_pred, age_group_pred, sample, mean_variance_loss, cross_entropy_loss\n",
    "    )\n",
    "    kinship_pred = kinship_module(embeddings)\n",
    "    kinship_loss = kinship_loss_func(kinship_pred, sample, cross_entropy_loss)\n",
    "    loss = fr_loss + age_loss + age_group_loss + kinship_loss\n",
    "    if _ % 10 == 0:\n",
    "        print(\n",
    "            f\"{_:4d},\\\n",
    "            loss: {tensor_to_int(loss):8.4f},\\\n",
    "            fr: {tensor_to_int(fr_loss):4.2f},\\\n",
    "            age: {tensor_to_int(age_loss):4.2f},\\\n",
    "            age_group: {tensor_to_int(age_group_loss):4.2f}\\\n",
    "            kinship: {tensor_to_int(kinship_loss):4.2f}\"\n",
    "        )\n",
    "\n",
    "    torch.nn.utils.clip_grad_norm_(face_age_model.parameters(), 5)\n",
    "    face_age_optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    face_age_optimizer.step()\n",
    "    lr_scheduler.step()\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
